---
title: "Untitled"
output: html_document
date: "2024-11-05"
---


```{r}
setwd("C:/Users/jake pc/Desktop/117")
responders_data_sheet <- read.csv(file="data(1).csv",header=TRUE)
```

Part 1: Hypothesis Testing
Use a Hypothesis Test to determine if responders and non-responders tend to have the same age.
Output: A written summary of the steps of your hypothesis test and the result of your test.



Normality test for ages of entire data set. 
```{r}
responders_data_sheet
population_ages <- responders_data_sheet[,2]
print(min(population_ages))
print(max(population_ages))
hist(population_ages)
shapiro.test(population_ages)
qqnorm(population_ages)
qqline(population_ages, col = "red")
```
By the histogram, shapiro-wilks test for normality, and QQ plot, the ages of the data set are evidently not normally distributed. 


Normality test for responders. 
```{r}
#ages of responders
target_1_ages <- responders_data_sheet[responders_data_sheet[,7] == 1,2]

hist(target_1_ages)
shapiro.test(target_1_ages)
qqnorm(target_1_ages)
qqline(target_1_ages, col = "red")
```
reject null hypotheis that the sample is normally distributed. 


Normality test for non-responders. 
```{r}
#ages of non-responders
target_0_ages <- responders_data_sheet[responders_data_sheet[,7] == 0,2]

hist(target_0_ages)
shapiro.test(target_0_ages)
qqnorm(target_0_ages)
qqline(target_0_ages, col = "red")
```
reject the null hypothesis that the sample is normally distributed. 

Non-parametric hypothesis test, HA: target_1 > target_0
```{r}
wilcox.test(target_1_ages, target_0_ages, alternative = "greater")
```
reject the null hypothesis that the mean age of responders is equal to the mean age of non-responders, and tentatively conclude that the mean age of responders is higher. 

From the histograms for both responders and non-responders, the frequency for both categories decrease from 80 to 95 due to decrease likelihood of being sampled from population by natural causes. 




Part 2: Predictive Modeling
Build a Binary Classifier to help this client better predict responders in future campaigns. 
Output: A brief writeup of your approach, including the algorithm you used, any data analysis or preparation you pursued, and the performance metrics you used to evaluate your final model.

1.) cleaning data 
```{r}
data_income <- responders_data_sheet[responders_data_sheet[, 4] != "", ]

income_levels <- factor(data_income[, "income"],
                                    levels = c("Under $10k", "10-19,999", "20-29,999", "30-39,999",
                                   "40-49,999", "50-59,999", "60-69,999", "70-79,999",
                                   "80-89,999", "90-99,999", "100-149,999", "150 - 174,999",
                                   "175 - 199,999", "200 - 249,999", "250k+"),
                                    ordered = TRUE)

#income levels 1:15, level 1 being under 10k, level 15 being 250k+
data_income$income <- as.numeric(income_levels)

probt_income_men <- data_income[data_income[,5]=="M",]

probt_income_women <- data_income[data_income[,5]=="F",]

responders_data_sheet_men <- data_income[data_income[,5]=="M",]

responders_data_sheet_women <- data_income[data_income[,5]=="F",]
```


we're going to build a logistic regression model to find the probability of response as a function of the other variable. 
```{r}
binary_classifier <- function(predictor, clean_data, color) {
  
  simple_logistic_model <- glm(data = clean_data,
                               target ~ predictor,
                               family = binomial())

  intercept_slope <- coef(simple_logistic_model)
  
  x_evaluation <- seq(min(predictor), max(predictor), length.out = 100)
  
  Prob_by_income <- function(x, intercept_slope) {
    log_odds <- intercept_slope[1] + intercept_slope[2] * x
    odds <- exp(log_odds)
    probability <- odds / (1 + odds)
    return(probability)
  }
  
  probabilities <- sapply(x_evaluation, function(x) Prob_by_income(x, intercept_slope))
  plot(x=x_evaluation,y=probabilities,col=color,xlim=range(min(x_evaluation - 5),max(x_evaluation+5)),ylim=range(0,.5),xlab="")
  legend("topleft", legend = c("Income", "Distance", "Age"),col = c("blue", "black", "red"), lty = 1, lwd = 2)
  min_prob <- min(probabilities)
  min_x <- x_evaluation[which.min(probabilities)]
  
  max_prob <- max(probabilities)
  max_x <- x_evaluation[which.max(probabilities)]
 
  delta_value <- as.numeric(tail(probabilities, 1) - head(probabilities, 1))
 
  delta_text <- paste0("Delta Prob %: ", round(delta_value*100))
  mtext(delta_text, side = 1, line = 3, col = "blue")
  
  points(min_x, min_prob, col = "black", pch = 19)
  
  text(min_x, min_prob - 0.02, labels = paste0("Min: ", round(min_prob, 3)), col = "blue")
  
  points(max_x, max_prob, col = "black", pch = 19)
  
  text(max_x, max_prob - 0.01, labels = paste0("Max: ", round(max_prob, 3)), col = "red")
  
  return(delta_value)

}
```

FOR BOTH GENDERS AND ALL MARITAL STATUS 
```{r}
par(mfrow = c(1, 3))
#income
binary_classifier(data_income$income,data_income,c("blue"))
#distance
binary_classifier(responders_data_sheet$dist,responders_data_sheet,c("black"))
#age
binary_classifier(responders_data_sheet$age,responders_data_sheet,c("red"))
```


```{r}
predictors <- list(probt_income_men$income,probt_income_women$income,
                   responders_data_sheet_men$dist,responders_data_sheet_women$dist,
                   responders_data_sheet_men$age,responders_data_sheet_women$age) 

clean_data_list <- list(probt_income_men,probt_income_women,
                        responders_data_sheet_men,responders_data_sheet_women,
                        responders_data_sheet_men,responders_data_sheet_women)


par(mfrow = c(1,2))

colors <- c("#1E90FF","#87CEFA","#32CD32","#98FB98","#8A2BE2","#DDA0DD")

deltas <- numeric(6)
deltas <- mapply(binary_classifier, predictor = predictors, clean_data = clean_data_list, color = colors)

delta_mat <- matrix(data = deltas, nrow = 3, ncol = 2, byrow = TRUE,
                    dimnames = list(c("income", "distance", "age"), 
                                    c("Male", "Female")))

(delta_mat)

```


Part 3: Data Visualization
Create a visualization of the Cumulative Gains Chart for your model. If you are unfamiliar, see here for more information: https://www.ibm.com/docs/en/spss-statistics/24.0.0?topic=overtraining-cumulative-gains-lift-charts

Output: The image of your Cumulative Gains Chart.

im going to categorize the continuous inputs of the logistic regression model in a manner I see as realistic 













1.) age: 60-80 and 80-100
2.) incomes: levels 0-4 (under 10k to 49,999) and remainders 
3.) distance was relatively insignificant as a predictor

find probability of responce given subject are in age 
category 80-100 and income levesl 1-4. 

this probability would be the subjects in this category who did respond divided by totall subjects in the category

```{r}


#LIFT

income_1to4_and_age_80to100 <- data_income[(data_income[,4] %in% c(1,2,3,4)) & (data_income[,2] %in% c(seq(80,100,by=1))),]

totall_posative_responces_stratification <- sum(income_1to4_and_age_80to100[,7])

totall_customers_stratification <- nrow(income_1to4_and_age_80to100)

prob_stratification <- totall_posative_responces_stratification / nrow(income_1to4_and_age_80to100)

(prob_stratification)



#BASELINE

totall_posative_responses <- sum(responders_data_sheet[,7])


totall_customers <- nrow(responders_data_sheet)

prob_baseline <- totall_posative_responses / nrow(responders_data_sheet)


(prob_baseline)





percent_contacted <- seq(.1,1,by=.1)


lift_chart_data <- function(percent_contacted) {
  
  lift_percent_pos <- numeric(length(percent_contacted))
  baseline_percent_pos <- numeric(length(percent_contacted))
  
for (i in 1:10) {
    lift_percent_pos[i] = percent_contacted[i]*totall_customers*prob_stratification/totall_posative_responses
    
    
    baseline_percent_pos[i] = percent_contacted[i]*totall_customers*prob_baseline/totall_posative_responses
    
}
  



  print(lift_percent_pos)
  print(baseline_percent_pos)
plot(x=percent_contacted,y=lift_percent_pos,col="red")

points(x=percent_contacted,y=baseline_percent_pos,col="blue")
}

lift_chart_data(percent_contacted)


```




Part 4: Brief Writeup
Provide an executive summary of your findings from tasks 1-3. Treat this as if you were sending an email to a teammate or your supervisor bringing them up to speed on your analysis and findings.


