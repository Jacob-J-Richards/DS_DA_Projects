{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir(\"/Users/jacobrichards/Desktop/DS_DA_Projects/3-90+_DaysPastDue/data\")\n",
    "\n",
    "train = pd.read_csv(\"train.csv\", na_values=[\"\", \"NA\"])\n",
    "\n",
    "test = pd.read_csv(\"test.csv\", na_values=[\"\", \"NA\"])\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = train['feature_3'].quantile(0.01)\n",
    "upper_bound = train['feature_3'].quantile(0.99)\n",
    "\n",
    "train = train[(train['feature_3'] >= lower_bound) & (train['feature_3'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_median = train['feature_3'].median()\n",
    "train['feature_3'].fillna(train_median, inplace=True)\n",
    "\n",
    "test_median = test['feature_3'].median()\n",
    "test['feature_3'].fillna(test_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train['date']).dt.year\n",
    "test['date'] = pd.to_datetime(test['date']).dt.year\n",
    "\n",
    "def impute_feature_2(df):\n",
    "    df = df.sort_values(by=['id', 'date'])\n",
    "    df['feature_2'] = df['feature_2'].fillna(method='ffill')\n",
    "    df['feature_2'] = df['feature_2'].fillna(method='bfill')\n",
    "    return df\n",
    "\n",
    "train = train.groupby('id', group_keys=False).apply(impute_feature_2)\n",
    "test = test.groupby('id', group_keys=False).apply(impute_feature_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['y'] = train['y'].apply(lambda x: 1 if x == \"90+DPD\" else 0 if x == \"active\" else x)\n",
    "test['y'] = test['y'].apply(lambda x: 1 if x == \"90+DPD\" else 0 if x == \"active\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train[['feature_1', 'feature_2', 'feature_3', 'feature_4']] = scaler.fit_transform(train[['feature_1', 'feature_2', 'feature_3', 'feature_4']])\n",
    "test[['feature_1', 'feature_2', 'feature_3', 'feature_4']] = scaler.transform(test[['feature_1', 'feature_2', 'feature_3', 'feature_4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['feature_1_x_feature_2'] = train['feature_1'] * train['feature_2']\n",
    "test['feature_1_x_feature_2'] = test['feature_1'] * test['feature_2']\n",
    "\n",
    "train['feature_1_x_feature_3'] = train['feature_1'] * train['feature_3']\n",
    "test['feature_1_x_feature_3'] = test['feature_1'] * test['feature_3']\n",
    "\n",
    "train['feature_1_x_feature_4'] = train['feature_1'] * train['feature_4']\n",
    "test['feature_1_x_feature_4'] = test['feature_1'] * test['feature_4']\n",
    "\n",
    "train['feature_2_x_feature_3'] = train['feature_2'] * train['feature_3']\n",
    "test['feature_2_x_feature_3'] = test['feature_2'] * test['feature_3']\n",
    "\n",
    "train['feature_2_x_feature_4'] = train['feature_2'] * train['feature_4']\n",
    "test['feature_2_x_feature_4'] = test['feature_2'] * test['feature_4']\n",
    "\n",
    "train['feature_3_x_feature_4'] = train['feature_3'] * train['feature_4']\n",
    "test['feature_3_x_feature_4'] = test['feature_3'] * test['feature_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTrain Data:\")\n",
    "print(f\"Total rows: {len(train)}\")\n",
    "print(f\"Number of defaults (y=1): {(train['y']==1).sum()}\")\n",
    "print(f\"Default rate: {(train['y']==1).mean():.2%}\")\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(f\"Total rows: {len(test)}\")\n",
    "print(f\"Number of defaults (y=1): {(test['y']==1).sum()}\")\n",
    "print(f\"Default rate: {(test['y']==1).mean():.2%}\")\n",
    "\n",
    "common_ids = set(train['id']) & set(test['id'])\n",
    "print(f\"\\nNumber of overlapping IDs between train and test: {len(common_ids)}\")\n",
    "if len(common_ids) > 0:\n",
    "    print(\"\\nOverlapping IDs:\")\n",
    "    print(common_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "def create_split_splines(data_train, data_test, interaction_term, n_knots=10, degree=3):\n",
    "    interaction_train = data_train[interaction_term[0]] * data_train[interaction_term[1]]\n",
    "    interaction_test = data_test[interaction_term[0]] * data_test[interaction_term[1]]\n",
    "    \n",
    "    spline_left = SplineTransformer(n_knots=n_knots, degree=degree)\n",
    "    spline_right = SplineTransformer(n_knots=n_knots, degree=degree)\n",
    "    \n",
    "    left_mask_train = interaction_train <= 0\n",
    "    right_mask_train = ~left_mask_train\n",
    "    left_mask_test = interaction_test <= 0 \n",
    "    right_mask_test = ~left_mask_test\n",
    "    \n",
    "    X_train_spline = np.zeros((len(data_train), 2 * n_knots + 2 * degree - 2))\n",
    "    X_test_spline = np.zeros((len(data_test), 2 * n_knots + 2 * degree - 2))\n",
    "    \n",
    "    n_features = n_knots + degree - 1\n",
    "    X_train_spline[left_mask_train, :n_features] = spline_left.fit_transform(interaction_train[left_mask_train].values.reshape(-1, 1))\n",
    "    X_train_spline[right_mask_train, n_features:] = spline_right.fit_transform(interaction_train[right_mask_train].values.reshape(-1, 1))\n",
    "    X_test_spline[left_mask_test, :n_features] = spline_left.transform(interaction_test[left_mask_test].values.reshape(-1, 1))\n",
    "    X_test_spline[right_mask_test, n_features:] = spline_right.transform(interaction_test[right_mask_test].values.reshape(-1, 1))\n",
    "    \n",
    "    return X_train_spline, X_test_spline, spline_left, spline_right\n",
    "\n",
    "features = ['feature_1', 'feature_2', 'feature_3', 'feature_4']\n",
    "splined_interactions = [['feature_1', 'feature_3'], ['feature_3', 'feature_4']]\n",
    "regular_interactions = [['feature_1', 'feature_2'], ['feature_2', 'feature_3'], ['feature_2', 'feature_4']]\n",
    "\n",
    "n_knots = 10\n",
    "degree = 3\n",
    "\n",
    "X_train = train[features]\n",
    "X_test = test[features]\n",
    "y_train = train['y']\n",
    "y_test = test['y']\n",
    "\n",
    "X_train_splines = [X_train]\n",
    "X_test_splines = [X_test]\n",
    "spline_transformers = {}\n",
    "\n",
    "for i, interaction in enumerate(splined_interactions):\n",
    "    X_train_spline, X_test_spline, spline_left, spline_right = create_split_splines(train, test, interaction)\n",
    "    X_train_splines.append(X_train_spline)\n",
    "    X_test_splines.append(X_test_spline)\n",
    "    spline_transformers[i] = (spline_left, spline_right)\n",
    "\n",
    "for interaction in regular_interactions:\n",
    "    X_train_splines.append((train[interaction[0]] * train[interaction[1]]).values.reshape(-1, 1))\n",
    "    X_test_splines.append((test[interaction[0]] * test[interaction[1]]).values.reshape(-1, 1))\n",
    "\n",
    "X_train_final = np.hstack(X_train_splines)\n",
    "X_test_final = np.hstack(X_test_splines)\n",
    "\n",
    "model = LogisticRegression(fit_intercept=True)\n",
    "model.fit(X_train_final, y_train)\n",
    "\n",
    "coefficients = pd.DataFrame(\n",
    "    {'Feature': features + \n",
    "     [f\"{interaction[0]}_x_{interaction[1]}_spline_{i}\" for interaction in splined_interactions for i in range(2 * n_knots + 2 * degree - 2)] +\n",
    "     [f\"{interaction[0]}_x_{interaction[1]}\" for interaction in regular_interactions],\n",
    "     'Coefficient': model.coef_[0]\n",
    "    })\n",
    "print(\"\\nModel Coefficients:\")\n",
    "print(coefficients)\n",
    "\n",
    "test_pred_proba = model.predict_proba(X_test_final)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, test_pred_proba)\n",
    "optimal_threshold = thresholds[np.argmin(np.abs(fpr - (1-tpr)))]\n",
    "y_pred = (test_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "final_recall = recall_score(y_test, y_pred)\n",
    "final_auc = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC Curve (Test Recall = {final_recall:.3f}, Test AUC = {final_auc:.3f})')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Optimal threshold: {optimal_threshold:.3f}\")\n",
    "print(f\"Final test recall at optimal threshold: {final_recall:.3f}\")\n",
    "print(f\"Final test AUC: {final_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "X = train[['feature_1', 'feature_2', 'feature_3', 'feature_4']]\n",
    "y = train['y']\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X, y)\n",
    "\n",
    "mean_values = X.mean()\n",
    "coefficients = lr_model.coef_[0]\n",
    "\n",
    "def create_plots(plot_type_left, plot_type_right, feature, n_bins):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    x_range = np.linspace(X[feature].min(), X[feature].max(), 100)\n",
    "    pred_data = np.tile(mean_values, (100, 1))\n",
    "    pred_data = pd.DataFrame(pred_data, columns=X.columns)\n",
    "    pred_data[feature] = x_range\n",
    "    y_pred = lr_model.predict_proba(pred_data)[:, 1]\n",
    "    \n",
    "    bins = pd.qcut(X[feature], q=n_bins, duplicates='drop')\n",
    "    bin_means = X.groupby(bins)[feature].mean()\n",
    "    bin_probs = train.groupby(bins)['y'].mean()\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x_range, y_pred, label='Predicted Probability', color='red')\n",
    "    sns.scatterplot(x=bin_means, y=bin_probs, color='blue', s=20, label='Observed Probability')\n",
    "    plt.text(0.05, 0.95, f'β{list(X.columns).index(feature)+1} = {coefficients[list(X.columns).index(feature)]:.3f}', transform=plt.gca().transAxes)\n",
    "    plt.title(f'Probabilities vs {feature}\\n(Other Variables at Mean)')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlim(X[feature].min(), X[feature].max())\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x_range, y_pred, label='Predicted Probability', color='red')\n",
    "    sns.scatterplot(x=bin_means, y=bin_probs, color='blue', s=20, label='Observed Probability')\n",
    "    plt.title(f'Probabilities vs {feature}\\n(Bins: {n_bins})')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlim(X[feature].min(), X[feature].max())\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_type_left = widgets.Dropdown(\n",
    "    options=['Predicted & Observed'],\n",
    "    description='Left Plot:',\n",
    "    value='Predicted & Observed'\n",
    ")\n",
    "\n",
    "plot_type_right = widgets.Dropdown(\n",
    "    options=['Predicted & Observed'],\n",
    "    description='Right Plot:',\n",
    "    value='Predicted & Observed'\n",
    ")\n",
    "\n",
    "feature_selector = widgets.Dropdown(\n",
    "    options=['feature_1', 'feature_2', 'feature_3', 'feature_4'],\n",
    "    description='Feature:',\n",
    "    value='feature_1'\n",
    ")\n",
    "\n",
    "bin_slider = widgets.IntSlider(\n",
    "    value=50,\n",
    "    min=10,\n",
    "    max=100,\n",
    "    step=5,\n",
    "    description='Bins:'\n",
    ")\n",
    "\n",
    "def on_change(change):\n",
    "    clear_output(wait=True)\n",
    "    display(plot_type_left)\n",
    "    display(plot_type_right)\n",
    "    display(feature_selector)\n",
    "    display(bin_slider)\n",
    "    create_plots(plot_type_left.value, plot_type_right.value, feature_selector.value, bin_slider.value)\n",
    "\n",
    "plot_type_left.observe(on_change, names='value')\n",
    "plot_type_right.observe(on_change, names='value')\n",
    "feature_selector.observe(on_change, names='value')\n",
    "bin_slider.observe(on_change, names='value')\n",
    "\n",
    "display(plot_type_left)\n",
    "display(plot_type_right)\n",
    "display(feature_selector)\n",
    "display(bin_slider)\n",
    "create_plots(plot_type_left.value, plot_type_right.value, feature_selector.value, bin_slider.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from scipy.interpolate import LSQUnivariateSpline\n",
    "\n",
    "X = train[['feature_1', 'feature_2', 'feature_3', 'feature_4']]\n",
    "y = train['y']\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X, y)\n",
    "\n",
    "mean_values = X.mean()\n",
    "coefficients = lr_model.coef_[0]\n",
    "\n",
    "def create_plots(feature, n_bins, knot1_val, knot2_val, knot3_val):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    bins = pd.qcut(X[feature], q=n_bins, duplicates='drop')\n",
    "    bin_means = X.groupby(bins)[feature].mean()\n",
    "    bin_probs = train.groupby(bins)['y'].mean()\n",
    "    \n",
    "    x_range = np.linspace(X[feature].min(), X[feature].max(), 100)\n",
    "    knots = np.array([knot1_val, knot2_val, knot3_val])\n",
    "    \n",
    "    spline = LSQUnivariateSpline(bin_means, bin_probs, knots, k=1)\n",
    "    y_pred = spline(x_range)\n",
    "    \n",
    "    plt.plot(x_range, y_pred, label='Piecewise Linear Fit', color='red')\n",
    "    sns.scatterplot(x=bin_means, y=bin_probs, color='blue', s=20, label='Observed Probability')\n",
    "    plt.vlines(knots, 0, 1, colors='green', linestyles='dashed', alpha=0.5, label='Knots')\n",
    "    plt.text(0.05, 0.95, f'β{list(X.columns).index(feature)+1} = {coefficients[list(X.columns).index(feature)]:.3f}', transform=plt.gca().transAxes)\n",
    "    plt.title(f'Probabilities vs {feature}\\n(Other Variables at Mean)')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlim(X[feature].min(), X[feature].max())\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    print(f\"Knot locations: {knots}\")\n",
    "    plt.show()\n",
    "\n",
    "feature_selector = widgets.Dropdown(\n",
    "    options=['feature_1', 'feature_2', 'feature_3', 'feature_4'],\n",
    "    description='Feature:',\n",
    "    value='feature_1'\n",
    ")\n",
    "\n",
    "bin_slider = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=10,\n",
    "    max=100,\n",
    "    step=5,\n",
    "    description='Bins:'\n",
    ")\n",
    "\n",
    "knot1 = widgets.FloatSlider(\n",
    "    value=X[feature_selector.value].min() + (X[feature_selector.value].max()-X[feature_selector.value].min())*0.25,\n",
    "    min=X[feature_selector.value].min() - 2,\n",
    "    max=X[feature_selector.value].max() + 2,\n",
    "    description='Knot 1:'\n",
    ")\n",
    "\n",
    "knot2 = widgets.FloatSlider(\n",
    "    value=X[feature_selector.value].min() + (X[feature_selector.value].max()-X[feature_selector.value].min())*0.5,\n",
    "    min=X[feature_selector.value].min() - 2,\n",
    "    max=X[feature_selector.value].max() + 2,\n",
    "    description='Knot 2:'\n",
    ")\n",
    "\n",
    "knot3 = widgets.FloatSlider(\n",
    "    value=X[feature_selector.value].min() + (X[feature_selector.value].max()-X[feature_selector.value].min())*0.75,\n",
    "    min=X[feature_selector.value].min() - 2,\n",
    "    max=X[feature_selector.value].max() + 2,\n",
    "    description='Knot 3:'\n",
    ")\n",
    "\n",
    "def on_change(change):\n",
    "    clear_output(wait=True)\n",
    "    display(feature_selector)\n",
    "    display(bin_slider)\n",
    "    display(knot1)\n",
    "    display(knot2)\n",
    "    display(knot3)\n",
    "    create_plots(feature_selector.value, bin_slider.value, knot1.value, knot2.value, knot3.value)\n",
    "\n",
    "feature_selector.observe(on_change, names='value')\n",
    "bin_slider.observe(on_change, names='value')\n",
    "knot1.observe(on_change, names='value')\n",
    "knot2.observe(on_change, names='value')\n",
    "knot3.observe(on_change, names='value')\n",
    "\n",
    "display(feature_selector)\n",
    "display(bin_slider)\n",
    "display(knot1)\n",
    "display(knot2)\n",
    "display(knot3)\n",
    "create_plots(feature_selector.value, bin_slider.value, knot1.value, knot2.value, knot3.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, recall_score, roc_auc_score, log_loss\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "def create_split_splines(data_train, data_test, interaction_term, n_knots=10, degree=3):\n",
    "    interaction_train = data_train[interaction_term[0]] * data_train[interaction_term[1]]\n",
    "    interaction_test = data_test[interaction_term[0]] * data_test[interaction_term[1]]\n",
    "    \n",
    "    spline_left = SplineTransformer(n_knots=n_knots, degree=degree)\n",
    "    spline_right = SplineTransformer(n_knots=n_knots, degree=degree)\n",
    "    \n",
    "    left_mask_train = interaction_train <= 0\n",
    "    right_mask_train = ~left_mask_train\n",
    "    left_mask_test = interaction_test <= 0 \n",
    "    right_mask_test = ~left_mask_test\n",
    "    \n",
    "    X_train_spline = np.zeros((len(data_train), 2 * n_knots + 2 * degree - 2))\n",
    "    X_test_spline = np.zeros((len(data_test), 2 * n_knots + 2 * degree - 2))\n",
    "    \n",
    "    n_features = n_knots + degree - 1\n",
    "    X_train_spline[left_mask_train, :n_features] = spline_left.fit_transform(interaction_train[left_mask_train].values.reshape(-1, 1))\n",
    "    X_train_spline[right_mask_train, n_features:] = spline_right.fit_transform(interaction_train[right_mask_train].values.reshape(-1, 1))\n",
    "    X_test_spline[left_mask_test, :n_features] = spline_left.transform(interaction_test[left_mask_test].values.reshape(-1, 1))\n",
    "    X_test_spline[right_mask_test, n_features:] = spline_right.transform(interaction_test[right_mask_test].values.reshape(-1, 1))\n",
    "    \n",
    "    return X_train_spline, X_test_spline, spline_left, spline_right\n",
    "\n",
    "features = ['feature_1', 'feature_2', 'feature_3', 'feature_4']\n",
    "splined_interactions = [['feature_1', 'feature_3'], ['feature_3', 'feature_4']]\n",
    "regular_interactions = [['feature_1', 'feature_2'], ['feature_2', 'feature_3'], ['feature_2', 'feature_4']]\n",
    "\n",
    "n_knots = 10\n",
    "degree = 3\n",
    "\n",
    "X_train = train[features]\n",
    "X_test = test[features]\n",
    "y_train = train['y']\n",
    "y_test = test['y']\n",
    "\n",
    "X_train_splines = [X_train]\n",
    "X_test_splines = [X_test]\n",
    "spline_transformers = {}\n",
    "\n",
    "for i, interaction in enumerate(splined_interactions):\n",
    "    X_train_spline, X_test_spline, spline_left, spline_right = create_split_splines(train, test, interaction)\n",
    "    X_train_splines.append(X_train_spline)\n",
    "    X_test_splines.append(X_test_spline)\n",
    "    spline_transformers[i] = (spline_left, spline_right)\n",
    "\n",
    "for interaction in regular_interactions:\n",
    "    X_train_splines.append((train[interaction[0]] * train[interaction[1]]).values.reshape(-1, 1))\n",
    "    X_test_splines.append((test[interaction[0]] * test[interaction[1]]).values.reshape(-1, 1))\n",
    "\n",
    "X_train_final = np.hstack(X_train_splines)\n",
    "X_test_final = np.hstack(X_test_splines)\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(128, 128), activation='relu', solver='sgd', learning_rate_init=0.01, random_state=42, warm_start=True)\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "max_epochs = 100\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    model.max_iter = epoch\n",
    "    model.partial_fit(X_train_final, y_train, classes=np.unique(y_train))\n",
    "    \n",
    "    train_pred_proba = model.predict_proba(X_train_final)\n",
    "    test_pred_proba = model.predict_proba(X_test_final)\n",
    "    \n",
    "    train_losses.append(log_loss(y_train, train_pred_proba))\n",
    "    test_losses.append(log_loss(y_test, test_pred_proba))\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(range(1, max_epochs + 1), train_losses, label=\"Training Loss\")\n",
    "ax1.plot(range(1, max_epochs + 1), test_losses, label=\"Test Loss\", linestyle=\"--\")\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_title(\"Train vs Test Loss Curve\")\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, train_pred_proba[:, 1])\n",
    "fpr_test, tpr_test, thresholds = roc_curve(y_test, test_pred_proba[:, 1])\n",
    "\n",
    "train_auc = roc_auc_score(y_train, train_pred_proba[:, 1])\n",
    "test_auc = roc_auc_score(y_test, test_pred_proba[:, 1])\n",
    "\n",
    "ax2.plot(fpr_train, tpr_train, label=f'Train (AUC = {train_auc:.3f})')\n",
    "ax2.plot(fpr_test, tpr_test, label=f'Test (AUC = {test_auc:.3f})')\n",
    "ax2.plot([0, 1], [0, 1], 'k--')\n",
    "ax2.set_xlabel('False Positive Rate')\n",
    "ax2.set_ylabel('True Positive Rate')\n",
    "ax2.set_title('ROC Curves: Train vs Test')\n",
    "ax2.legend()\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "thresholds_range = np.linspace(0, 1, 100)\n",
    "\n",
    "for threshold in thresholds_range:\n",
    "    train_pred = (train_pred_proba[:, 1] >= threshold).astype(int)\n",
    "    test_pred = (test_pred_proba[:, 1] >= threshold).astype(int)\n",
    "    train_scores.append(recall_score(y_train, train_pred))\n",
    "    test_scores.append(recall_score(y_test, test_pred))\n",
    "\n",
    "ax3.plot(thresholds_range, train_scores, label='Train')\n",
    "ax3.plot(thresholds_range, test_scores, label='Test')\n",
    "ax3.set_xlabel('Threshold')\n",
    "ax3.set_ylabel('Recall Score')\n",
    "ax3.set_title('Recall vs Threshold: Train vs Test')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6.4, 4.8))\n",
    "plt.plot(fpr_test, tpr_test, label=f'Test (AUC = {test_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "fnr = 1 - tpr_test\n",
    "optimal_idx = np.argmin(np.abs(fpr_test - fnr))\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "y_pred = (test_pred_proba[:, 1] >= optimal_threshold).astype(int)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Train AUC: {train_auc:.3f}\")\n",
    "print(f\"Test AUC: {test_auc:.3f}\")\n",
    "print(f\"Optimal threshold: {optimal_threshold:.3f}\")\n",
    "print(f\"Recall at optimal threshold: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def create_splines(data_train, data_test, feature, n_knots, degree):\n",
    "    spline = SplineTransformer(n_knots=n_knots, degree=degree)\n",
    "    \n",
    "    X_train_spline = spline.fit_transform(data_train[feature].values.reshape(-1, 1))\n",
    "    X_test_spline = spline.transform(data_test[feature].values.reshape(-1, 1))\n",
    "    \n",
    "    return X_train_spline, X_test_spline\n",
    "\n",
    "features = ['feature_1', 'feature_2', 'feature_3', 'feature_4']\n",
    "feature_pairs = [(i, j) for i in features for j in features if i < j]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'spline_n_knots': [3, 5, 7],\n",
    "    'spline_degree': [2, 3, 4]\n",
    "}\n",
    "\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "best_model = None\n",
    "best_X_train = None\n",
    "best_X_test = None\n",
    "\n",
    "for n_knots in param_grid['spline_n_knots']:\n",
    "    for degree in param_grid['spline_degree']:\n",
    "        X_train_splines = []\n",
    "        X_test_splines = []\n",
    "        \n",
    "        for feature in features:\n",
    "            X_train_spline, X_test_spline = create_splines(train, test, feature, n_knots, degree)\n",
    "            X_train_splines.append(X_train_spline)\n",
    "            X_test_splines.append(X_test_spline)\n",
    "\n",
    "        X_train_interactions = []\n",
    "        X_test_interactions = []\n",
    "\n",
    "        for pair in feature_pairs:\n",
    "            interaction_train = train[pair[0]] * train[pair[1]]\n",
    "            interaction_test = test[pair[0]] * test[pair[1]]\n",
    "            X_train_interactions.append(interaction_train.values.reshape(-1, 1))\n",
    "            X_test_interactions.append(interaction_test.values.reshape(-1, 1))\n",
    "\n",
    "        X_train_final = np.hstack(X_train_splines + X_train_interactions)\n",
    "        X_test_final = np.hstack(X_test_splines + X_test_interactions)\n",
    "\n",
    "        base_model = LogisticRegression(solver='liblinear')\n",
    "        grid_search = GridSearchCV(\n",
    "            base_model,\n",
    "            {'C': param_grid['C'], 'penalty': param_grid['penalty']},\n",
    "            cv=5,\n",
    "            scoring='roc_auc'\n",
    "        )\n",
    "        grid_search.fit(X_train_final, train['y'])\n",
    "        \n",
    "        if grid_search.best_score_ > best_score:\n",
    "            best_score = grid_search.best_score_\n",
    "            best_params = {\n",
    "                'C': grid_search.best_params_['C'],\n",
    "                'penalty': grid_search.best_params_['penalty'],\n",
    "                'spline_n_knots': n_knots,\n",
    "                'spline_degree': degree\n",
    "            }\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_X_train = X_train_final\n",
    "            best_X_test = X_test_final\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(best_params)\n",
    "\n",
    "feature_names = []\n",
    "for feature in features:\n",
    "    feature_names.extend([f\"{feature}_spline_{i}\" for i in range(best_params['spline_n_knots'] + best_params['spline_degree'] - 1)])\n",
    "for pair in feature_pairs:\n",
    "    feature_names.append(f\"{pair[0]}_x_{pair[1]}\")\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': best_model.coef_[0]\n",
    "})\n",
    "print(\"\\nModel Coefficients:\")\n",
    "print(coefficients)\n",
    "\n",
    "test_pred_proba = best_model.predict_proba(best_X_test)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, test_pred_proba)\n",
    "optimal_threshold = thresholds[np.argmin(np.abs(fpr - (1-tpr)))]\n",
    "y_pred = (test_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "final_recall = recall_score(y_test, y_pred)\n",
    "final_auc = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC Curve (Test Recall = {final_recall:.3f}, Test AUC = {final_auc:.3f})')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Optimal threshold: {optimal_threshold:.3f}\")\n",
    "print(f\"Final test recall at optimal threshold: {final_recall:.3f}\")\n",
    "print(f\"Final test AUC: {final_auc:.3f}\")\n",
    "\n",
    "print(\"\\nModel Components:\")\n",
    "print(\"\\nSplined Main Effects:\")\n",
    "for feature in features:\n",
    "    print(f\"- {feature}\")\n",
    "\n",
    "print(\"\\nInteraction Terms:\")\n",
    "for pair in feature_pairs:\n",
    "    print(f\"- {pair[0]} × {pair[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from itertools import combinations, product\n",
    "\n",
    "def create_splines(data_train, data_test, feature, n_knots=3, degree=2):\n",
    "    spline = SplineTransformer(n_knots=n_knots, degree=degree)\n",
    "    X_train_spline = spline.fit_transform(data_train[feature].values.reshape(-1, 1))\n",
    "    X_test_spline = spline.transform(data_test[feature].values.reshape(-1, 1))\n",
    "    return X_train_spline, X_test_spline\n",
    "\n",
    "features = ['feature_1', 'feature_2', 'feature_3', 'feature_4']\n",
    "feature_pairs = [(i, j) for i in features for j in features if i < j]\n",
    "\n",
    "results = []\n",
    "for r in range(len(features) + 1):\n",
    "    for splined_features in combinations(features, r):\n",
    "        for s in range(len(feature_pairs) + 1):\n",
    "            for interaction_pairs in combinations(feature_pairs, s):\n",
    "                X_train_components = []\n",
    "                X_test_components = []\n",
    "                \n",
    "                feature_names = []\n",
    "                \n",
    "                for feature in features:\n",
    "                    if feature in splined_features:\n",
    "                        X_train_spline, X_test_spline = create_splines(train, test, feature)\n",
    "                        X_train_components.append(X_train_spline)\n",
    "                        X_test_components.append(X_test_spline)\n",
    "                        feature_names.extend([f\"{feature}_spline_{i}\" for i in range(3 + 2 - 1)])\n",
    "                    else:\n",
    "                        X_train_components.append(train[feature].values.reshape(-1, 1))\n",
    "                        X_test_components.append(test[feature].values.reshape(-1, 1))\n",
    "                        feature_names.append(feature)\n",
    "\n",
    "                for pair in interaction_pairs:\n",
    "                    interaction_train = train[pair[0]] * train[pair[1]]\n",
    "                    interaction_test = test[pair[0]] * test[pair[1]]\n",
    "                    X_train_components.append(interaction_train.values.reshape(-1, 1))\n",
    "                    X_test_components.append(interaction_test.values.reshape(-1, 1))\n",
    "                    feature_names.append(f\"{pair[0]}_x_{pair[1]}\")\n",
    "\n",
    "                X_train_final = np.hstack(X_train_components)\n",
    "                X_test_final = np.hstack(X_test_components)\n",
    "\n",
    "                model = LogisticRegression(C=10, penalty='l1', solver='liblinear')\n",
    "                model.fit(X_train_final, train['y'])\n",
    "\n",
    "                test_pred_proba = model.predict_proba(X_test_final)[:, 1]\n",
    "                fpr, tpr, thresholds = roc_curve(y_test, test_pred_proba)\n",
    "                optimal_threshold = thresholds[np.argmin(np.abs(fpr - (1-tpr)))]\n",
    "                y_pred = (test_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "                recall = recall_score(y_test, y_pred)\n",
    "                auc = roc_auc_score(y_test, test_pred_proba)\n",
    "                score = recall + auc\n",
    "\n",
    "                results.append({\n",
    "                    'splined_features': splined_features,\n",
    "                    'interaction_terms': interaction_pairs,\n",
    "                    'recall': recall,\n",
    "                    'auc': auc,\n",
    "                    'total_score': score\n",
    "                })\n",
    "\n",
    "results.sort(key=lambda x: x['total_score'], reverse=True)\n",
    "\n",
    "print(\"\\nResults sorted by total score (recall + AUC):\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\n{i+1}. Total Score: {result['total_score']:.3f}\")\n",
    "    print(f\"Recall: {result['recall']:.3f}\")\n",
    "    print(f\"AUC: {result['auc']:.3f}\")\n",
    "    print(\"Splined Features:\", ', '.join(result['splined_features']) if result['splined_features'] else 'None')\n",
    "    print(\"Interaction Terms:\", ', '.join([f\"({p[0]} × {p[1]})\" for p in result['interaction_terms']]) if result['interaction_terms'] else 'None')\n",
    "\n",
    "best_result = results[0]\n",
    "print(\"\\nBest Combination:\")\n",
    "print(f\"Total Score: {best_result['total_score']:.3f}\")\n",
    "print(f\"Recall: {best_result['recall']:.3f}\")\n",
    "print(f\"AUC: {best_result['auc']:.3f}\")\n",
    "print(\"Splined Features:\", ', '.join(best_result['splined_features']) if best_result['splined_features'] else 'None')\n",
    "print(\"Interaction Terms:\", ', '.join([f\"({p[0]} × {p[1]})\" for p in best_result['interaction_terms']]) if best_result['interaction_terms'] else 'None')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
