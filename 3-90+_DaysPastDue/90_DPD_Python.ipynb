{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir(\"/Users/jacobrichards/Desktop/DS_DA_Projects/3-90+_DaysPastDue/Data_Files\")\n",
    "\n",
    "train = pd.read_csv(\"FITB_train.csv\", na_values=[\"\", \"NA\"])\n",
    "\n",
    "test = pd.read_csv(\"FITB_test.csv\", na_values=[\"\", \"NA\"])\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove upper and lower 1% of feature 3 for train but not test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = train['feature_3'].quantile(0.01)\n",
    "upper_bound = train['feature_3'].quantile(0.99)\n",
    "\n",
    "train = train[(train['feature_3'] >= lower_bound) & (train['feature_3'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace na with median value for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_median = train['feature_3'].median()\n",
    "train['feature_3'].fillna(train_median, inplace=True)\n",
    "\n",
    "test_median = test['feature_3'].median()\n",
    "test['feature_3'].fillna(test_median, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace na of feature 2 with forward fill and backward fill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train['date']).dt.year\n",
    "test['date'] = pd.to_datetime(test['date']).dt.year\n",
    "\n",
    "def impute_feature_2(df):\n",
    "    df = df.sort_values(by=['id', 'date'])\n",
    "    df['feature_2'] = df['feature_2'].fillna(method='ffill')\n",
    "    df['feature_2'] = df['feature_2'].fillna(method='bfill')\n",
    "    return df\n",
    "\n",
    "train = train.groupby('id', group_keys=False).apply(impute_feature_2)\n",
    "test = test.groupby('id', group_keys=False).apply(impute_feature_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace y with 1 if 90+DPD and 0 if active "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['y'] = train['y'].apply(lambda x: 1 if x == \"90+DPD\" else 0 if x == \"active\" else x)\n",
    "test['y'] = test['y'].apply(lambda x: 1 if x == \"90+DPD\" else 0 if x == \"active\" else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train[['feature_1', 'feature_2', 'feature_3', 'feature_4']] = scaler.fit_transform(train[['feature_1', 'feature_2', 'feature_3', 'feature_4']])\n",
    "test[['feature_1', 'feature_2', 'feature_3', 'feature_4']] = scaler.transform(test[['feature_1', 'feature_2', 'feature_3', 'feature_4']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "produce interaction terms (once significant interactions were found in the EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['feature_1_x_feature_2'] = train['feature_1'] * train['feature_2']\n",
    "test['feature_1_x_feature_2'] = test['feature_1'] * test['feature_2']\n",
    "train['feature_1_x_feature_3'] = train['feature_1'] * train['feature_3']\n",
    "test['feature_1_x_feature_3'] = test['feature_1'] * test['feature_3']\n",
    "train['feature_2_x_feature_3'] = train['feature_2'] * train['feature_3']\n",
    "test['feature_2_x_feature_3'] = test['feature_2'] * test['feature_3']\n",
    "train['feature_2_x_feature_4'] = train['feature_2'] * train['feature_4']\n",
    "test['feature_2_x_feature_4'] = test['feature_2'] * test['feature_4']\n",
    "train['feature_3_x_feature_4'] = train['feature_3'] * train['feature_4']\n",
    "test['feature_3_x_feature_4'] = test['feature_3'] * test['feature_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "standardizing the interaction terms made it worse, probably because they're not normally distributed so the z-scores would be meaningless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with interaction terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "X_train = train[['feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
    "                 'feature_1_x_feature_2', 'feature_1_x_feature_3',\n",
    "                 'feature_2_x_feature_3', 'feature_2_x_feature_4',\n",
    "                 'feature_3_x_feature_4']]\n",
    "y_train = train['y']\n",
    "\n",
    "model = LogisticRegression(fit_intercept=True)\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_test = test[['feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
    "               'feature_1_x_feature_2', 'feature_1_x_feature_3',\n",
    "               'feature_2_x_feature_3', 'feature_2_x_feature_4',\n",
    "               'feature_3_x_feature_4']]\n",
    "y_test = test['y']\n",
    "y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve on Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimal threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "fnr = 1 - tpr\n",
    "optimal_idx = np.argmin(np.abs(fpr - fnr))\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "print(f\"Optimal threshold: {optimal_threshold:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "\n",
    "y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"\\nRecall at optimal threshold: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability - Log(ods) - Observed Probability curves of predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = train[['feature_1', 'feature_2', 'feature_3', 'feature_4']]\n",
    "y = train['y']\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X, y)\n",
    "\n",
    "fig1, ((ax1, ax2, ax3, ax4), (ax5, ax6, ax7, ax8), (ax9, ax10, ax11, ax12)) = plt.subplots(3, 4, figsize=(20, 18))\n",
    "\n",
    "mean_values = X.mean()\n",
    "coefficients = lr_model.coef_[0]\n",
    "\n",
    "for i, feature in enumerate(['feature_1', 'feature_2', 'feature_3', 'feature_4']):\n",
    "    x_range = np.linspace(X[feature].min(), X[feature].max(), 100)\n",
    "    \n",
    "    pred_data = np.tile(mean_values, (100, 1))\n",
    "    pred_data = pd.DataFrame(pred_data, columns=X.columns)\n",
    "    pred_data[feature] = x_range\n",
    "    \n",
    "    y_pred = lr_model.predict_proba(pred_data)[:, 1]\n",
    "    \n",
    "    axes_top = [ax1, ax2, ax3, ax4]\n",
    "    axes_top[i].plot(x_range, y_pred, label='Predicted Probability')\n",
    "    axes_top[i].text(0.05, 0.95, f'Î²{i+1} = {coefficients[i]:.3f}', transform=axes_top[i].transAxes)\n",
    "    axes_top[i].set_title(f'Predicted Probability vs {feature}\\n(Other Variables at Mean)')\n",
    "    axes_top[i].set_ylabel('Predicted Probability')\n",
    "    axes_top[i].set_xlabel(feature)\n",
    "    axes_top[i].grid(True, alpha=0.3)\n",
    "    axes_top[i].set_ylim(0, 1)\n",
    "    axes_top[i].legend()\n",
    "    \n",
    "    X_with_const = sm.add_constant(X)\n",
    "    logit_model = sm.Logit(y, X_with_const)\n",
    "    result = logit_model.fit()\n",
    "    \n",
    "    feature_values = np.linspace(X[feature].min(), X[feature].max(), 50)\n",
    "    fixed_predictors = mean_values.copy()\n",
    "    log_odds = []\n",
    "    \n",
    "    for value in feature_values:\n",
    "        temp_predictors = fixed_predictors.copy()\n",
    "        temp_predictors[feature] = value\n",
    "        predictors_with_const = sm.add_constant(temp_predictors.values.reshape(1, -1), has_constant='add')\n",
    "        logit = np.dot(predictors_with_const, result.params)\n",
    "        log_odds.append(logit[0])\n",
    "    \n",
    "    plot_df = pd.DataFrame({\n",
    "        feature: feature_values,\n",
    "        'log_odds': log_odds\n",
    "    })\n",
    "    \n",
    "    axes_middle = [ax5, ax6, ax7, ax8]\n",
    "    sns.scatterplot(x=feature, y='log_odds', data=plot_df, color='blue', s=50, \n",
    "                    ax=axes_middle[i], label='Logit Points')\n",
    "    sns.regplot(x=feature, y='log_odds', data=plot_df, scatter=False, lowess=True,\n",
    "                color='red', line_kws={'lw': 2}, ax=axes_middle[i], label='Smoothed Logit Curve')\n",
    "    \n",
    "    axes_middle[i].set_title(f'Logit Curve (Log Odds) for {feature}')\n",
    "    axes_middle[i].set_xlabel(feature)\n",
    "    axes_middle[i].set_ylabel('Log(P / 1-P)')\n",
    "    axes_middle[i].axhline(0, color='grey', linestyle='--', label='Log Odds = 0')\n",
    "    axes_middle[i].legend()\n",
    "    axes_middle[i].grid(True)\n",
    "    \n",
    "    bins = pd.qcut(X[feature], q=50, duplicates='drop')\n",
    "    bin_means = X.groupby(bins)[feature].mean()\n",
    "    bin_probs = train.groupby(bins)['y'].mean()\n",
    "    \n",
    "    axes_bottom = [ax9, ax10, ax11, ax12]\n",
    "    sns.scatterplot(x=bin_means, y=bin_probs, ax=axes_bottom[i], color='blue', s=20, label='Observed Probability')\n",
    "    sns.regplot(x=bin_means, y=bin_probs, scatter=False, lowess=True,\n",
    "                color='red', line_kws={'lw': 2}, ax=axes_bottom[i], label='Smoothed Curve')\n",
    "    \n",
    "    axes_bottom[i].set_title(f'Observed Probability vs {feature}')\n",
    "    axes_bottom[i].set_xlabel(feature)\n",
    "    axes_bottom[i].set_ylabel('Probability of Positive Outcome')\n",
    "    axes_bottom[i].set_ylim(0, 1)\n",
    "    axes_bottom[i].legend()\n",
    "    axes_bottom[i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it appears the reason that feature 1 has such a weaker negative term coeficient is becuase it has some left tail outliers which weaken it's over all trend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
    "           'feature_1_x_feature_2', 'feature_1_x_feature_3', \n",
    "           'feature_2_x_feature_3', 'feature_2_x_feature_4',\n",
    "           'feature_3_x_feature_4']]\n",
    "y = train['y']\n",
    "\n",
    "fig1, ((ax1, ax2, ax3), (ax4, ax5, _)) = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = [ax1, ax2, ax3, ax4, ax5]\n",
    "\n",
    "interaction_terms = ['feature_1_x_feature_2', 'feature_1_x_feature_3', \n",
    "                    'feature_2_x_feature_3', 'feature_2_x_feature_4', \n",
    "                    'feature_3_x_feature_4']\n",
    "\n",
    "for i, feature in enumerate(interaction_terms):\n",
    "    bins = pd.qcut(X[feature], q=50, duplicates='drop')\n",
    "    bin_means = X.groupby(bins)[feature].mean()\n",
    "    bin_probs = train.groupby(bins)['y'].mean()\n",
    "    \n",
    "    sns.scatterplot(x=bin_means, y=bin_probs, ax=axes[i], color='blue', s=20, label='Observed Probability')\n",
    "    sns.regplot(x=bin_means, y=bin_probs, scatter=False, lowess=True,\n",
    "                color='red', line_kws={'lw': 2}, ax=axes[i], label='Smoothed Curve')\n",
    "    \n",
    "    axes[i].set_title(f'Observed Probability vs {feature}')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Probability of Positive Outcome')\n",
    "    axes[i].set_ylim(0, 1)\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Multi-collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Correlation Matrix\n",
    "correlation_matrix = train[['feature_1', 'feature_2', 'feature_3', 'feature_4']].corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(train['feature_1'], train['feature_3'], alpha=0.5)\n",
    "corr = train['feature_1'].corr(train['feature_3'])\n",
    "pct_between = (train['feature_3'][(train['feature_3'] >= 8) & (train['feature_3'] <= 14)].count() / train['feature_3'].count()) * 100\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 3')\n",
    "plt.title(f'Feature 1 vs Feature 3 Scatter Plot\\nCorrelation: {corr:.3f}\\n{pct_between:.1f}% of Feature 3 between 8-14')\n",
    "plt.show()\n",
    "\n",
    "filtered_data = train[~((train['feature_3'] >= 8) & (train['feature_3'] <= 14))]\n",
    "pct_remaining = (len(filtered_data) / len(train)) * 100\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(filtered_data['feature_1'], filtered_data['feature_3'], alpha=0.5)\n",
    "sns.regplot(x=filtered_data['feature_1'], y=filtered_data['feature_3'], scatter=False, lowess=True, color='red')\n",
    "corr = filtered_data['feature_1'].corr(filtered_data['feature_3'])\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 3')\n",
    "plt.title(f'Feature 1 vs Feature 3 Scatter Plot (Filtered)\\nCorrelation: {corr:.3f}\\n{pct_remaining:.1f}% of total observations')\n",
    "plt.xlim(-2, 2)\n",
    "plt.ylim(-2, 2)\n",
    "plt.show()\n",
    "\n",
    "zoomed_data = train[(train['feature_1'] >= -1.25) & (train['feature_1'] <= 1) & \n",
    "                    (train['feature_3'] >= -1) & (train['feature_3'] <= 0.5)]\n",
    "pct_zoomed = (len(zoomed_data) / len(train)) * 100\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(zoomed_data['feature_1'], zoomed_data['feature_3'], alpha=0.5)\n",
    "corr = zoomed_data['feature_1'].corr(zoomed_data['feature_3'])\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 3')\n",
    "plt.title(f'Feature 1 vs Feature 3 Scatter Plot (Zoomed)\\nCorrelation: {corr:.3f}\\n{pct_zoomed:.1f}% of total observations')\n",
    "plt.xlim(-1.25, 1)\n",
    "plt.ylim(-1.25, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "any attempt made to deal with this results in the model becoming weaker, since our goal is predictive performance is doesn't actually matter but it would be nice if we could produce a cleaner model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "computationally our coefficients are unstable yet the results are good so. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main drivers Visualizations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features 1 and 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "positive_data = train[train['y'] == 1]\n",
    "negative_data = train[train['y'] == 0]\n",
    "\n",
    "sns.kdeplot(data=positive_data['feature_1'], ax=ax, fill=True, alpha=0.6, label='Feature 1 (Positive)', color='darkgreen')\n",
    "sns.kdeplot(data=negative_data['feature_1'], ax=ax, fill=True, alpha=0.6, label='Feature 1 (Negative)', color='black')\n",
    "sns.kdeplot(data=positive_data['feature_3'], ax=ax, fill=True, alpha=0.6, label='Feature 3 (Positive)', color='lightgreen')\n",
    "sns.kdeplot(data=negative_data['feature_3'], ax=ax, fill=True, alpha=0.6, label='Feature 3 (Negative)', color='black')\n",
    "ax.set_title('Distribution by Outcome: Features 1 & 3')\n",
    "ax.set_xlabel('Value')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_xlim(-1.5, 1.5)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significantly different means of the positive negative outcomes for features 1 and 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features 2 and 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "positive_data = train[train['y'] == 1]\n",
    "negative_data = train[train['y'] == 0]\n",
    "\n",
    "pos_corr = positive_data['feature_2'].corr(positive_data['feature_4'])\n",
    "neg_corr = negative_data['feature_2'].corr(negative_data['feature_4'])\n",
    "\n",
    "sns.scatterplot(data=train, x='feature_2', y='feature_4', hue='y',\n",
    "                palette={1: 'green', 0: 'red'}, alpha=0.6)\n",
    "\n",
    "x_pos = positive_data['feature_2']\n",
    "y_pos = pos_corr * x_pos + (positive_data['feature_4'].mean() - pos_corr * positive_data['feature_2'].mean())\n",
    "plt.plot(x_pos, y_pos, color='darkgreen', linestyle='--')\n",
    "\n",
    "x_neg = negative_data['feature_2']\n",
    "y_neg = neg_corr * x_neg + (negative_data['feature_4'].mean() - neg_corr * negative_data['feature_2'].mean())\n",
    "plt.plot(x_neg, y_neg, color='darkred', linestyle='--')\n",
    "\n",
    "plt.title(f'Feature 2 vs Feature 4 by Outcome\\nPositive Correlation: {pos_corr:.3f}, Negative Correlation: {neg_corr:.3f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['feature_1', 'feature_2', 'feature_3', 'feature_4', \n",
    "           'feature_1_x_feature_2', 'feature_1_x_feature_3',\n",
    "           'feature_2_x_feature_3', 'feature_2_x_feature_4', 'feature_3_x_feature_4']]\n",
    "y = train['y']\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X, y)\n",
    "\n",
    "fig1, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 12))\n",
    "\n",
    "mean_values = X.mean()\n",
    "interaction_range = np.linspace(train['feature_2_x_feature_4'].min(), train['feature_2_x_feature_4'].max(), 100)\n",
    "\n",
    "pred_data = np.tile(mean_values, (100, 1))\n",
    "pred_data = pd.DataFrame(pred_data, columns=X.columns)\n",
    "pred_data['feature_2_x_feature_4'] = interaction_range\n",
    "\n",
    "y_pred = lr_model.predict_proba(pred_data)[:, 1]\n",
    "\n",
    "ax1.plot(interaction_range, y_pred)\n",
    "ax1.set_title('Predicted Probability vs feature_2 Ã feature_4\\n(Other Features and Interactions at Mean)')\n",
    "ax1.set_ylabel('Predicted Probability')\n",
    "ax1.set_xlabel('feature_2 Ã feature_4')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "bins = pd.qcut(X['feature_2_x_feature_4'], q=50, duplicates='drop')\n",
    "bin_means = X.groupby(bins)['feature_2_x_feature_4'].mean()\n",
    "bin_probs = train.groupby(bins)['y'].mean()\n",
    "\n",
    "sns.scatterplot(x=bin_means, y=bin_probs, ax=ax2, color='blue', s=20, label='Observed Probability')\n",
    "sns.regplot(x=bin_means, y=bin_probs, scatter=False, lowess=True,\n",
    "            color='red', line_kws={'lw': 2}, ax=ax2, label='Smoothed Curve')\n",
    "\n",
    "ax2.set_title('Observed Probability vs feature_2 Ã feature_4')\n",
    "ax2.set_xlabel('feature_2 Ã feature_4')\n",
    "ax2.set_ylabel('Probability of Positive Outcome')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig2, ax3 = plt.subplots(figsize=(20, 12))\n",
    "ax3.plot(interaction_range, y_pred, label='Predicted Probability')\n",
    "sns.scatterplot(x=bin_means, y=bin_probs, ax=ax3, color='blue', s=20, label='Observed Probability')\n",
    "sns.regplot(x=bin_means, y=bin_probs, scatter=False, lowess=True,\n",
    "            color='red', line_kws={'lw': 2}, ax=ax3, label='Smoothed Curve')\n",
    "\n",
    "ax3.set_title('Combined: Predicted and Observed Probabilities vs feature_2 Ã feature_4')\n",
    "ax3.set_xlabel('feature_2 Ã feature_4')\n",
    "ax3.set_ylabel('Probability')\n",
    "ax3.set_ylim(0, 1)\n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thus the interaction term produced for features 2 and 4 had a highly predictive coefficient. \n",
    "\n",
    "\n",
    "This is not mutually exclusive with the trend of feature 2 being negatively associated with positive outcomes as when feature 2 and feature 4 are within this range of each other is where the positives are located, thus when we give features 2 and 4 their own interaction term which is highly associated with positive outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "formula = 'y ~ feature_2 * feature_4'\n",
    "model = sm.Logit.from_formula(formula, data=train).fit()\n",
    "interaction_pvalue = model.pvalues['feature_2:feature_4']\n",
    "\n",
    "feature_2_values = np.linspace(train['feature_2'].min(), train['feature_2'].max(), 100)\n",
    "feature_4_levels = list(np.percentile(train['feature_4'], [25, 50, 75])) + [-4]\n",
    "\n",
    "for feature_4_level in feature_4_levels:\n",
    "    df = pd.DataFrame({\n",
    "        'feature_2': feature_2_values,\n",
    "        'feature_4': feature_4_level\n",
    "    })\n",
    "    df['interaction'] = df['feature_2'] * df['feature_4']\n",
    "    df['predicted_prob'] = model.predict(sm.add_constant(df))\n",
    "    \n",
    "    ax.plot(df['feature_2'], df['predicted_prob'], \n",
    "           label=f'feature_4={feature_4_level:.1f}')\n",
    "\n",
    "ax.set_xlabel('feature_2')\n",
    "ax.set_ylabel('Predicted Probability y = 1')\n",
    "ax.legend()\n",
    "ax.set_title(f'Interaction: feature_2 and feature_4\\nInteraction p-value: {interaction_pvalue:.4f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if interaction_pvalue < 0.05:\n",
    "    print(\"\\nSignificant interaction (p < 0.05):\")\n",
    "    print(\"feature_2 x feature_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model - slightly superior performance but still significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train = train[['feature_1', 'feature_2', 'feature_3', 'feature_4']]\n",
    "y_train = train['y']\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train);\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "X_test = test[['feature_1', 'feature_2', 'feature_3', 'feature_4']]\n",
    "y_test = test['y']\n",
    "\n",
    "\n",
    "rf_pred_proba = rf_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, rf_pred_proba)\n",
    "auc_score = roc_auc_score(y_test, rf_pred_proba)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc_score:.3f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Random Forest')\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, rf_pred_proba)\n",
    "fnr = 1 - tpr\n",
    "optimal_idx = np.argmin(np.abs(fpr - fnr))\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "print(f\"Optimal threshold: {optimal_threshold:.3f}\")\n",
    "\n",
    "\n",
    "y_pred = (rf_pred_proba >= optimal_threshold).astype(int)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"\\nRecall at optimal threshold: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORE EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "positive_data = train[train['y'] == 1]\n",
    "negative_data = train[train['y'] == 0]\n",
    "\n",
    "sns.kdeplot(data=positive_data['feature_2'], ax=ax, fill=True, alpha=0.6, label='Feature 2 (Positive)', color='darkgreen')\n",
    "sns.kdeplot(data=negative_data['feature_2'], ax=ax, fill=True, alpha=0.6, label='Feature 2 (Negative)', color='grey')\n",
    "sns.kdeplot(data=positive_data['feature_4'], ax=ax, fill=True, alpha=0.6, label='Feature 4 (Positive)', color='blue')\n",
    "sns.kdeplot(data=negative_data['feature_4'], ax=ax, fill=True, alpha=0.6, label='Feature 4 (Negative)', color='black')\n",
    "ax.set_title('Distribution by Outcome: Features 2 & 4')\n",
    "ax.set_xlabel('Value')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_xlim(-10, 10)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
