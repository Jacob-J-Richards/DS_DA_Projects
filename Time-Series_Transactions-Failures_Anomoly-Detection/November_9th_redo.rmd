---
title: "Untitled"
output: html_document
date: "2024-11-09"
---

1.1.1 Which dimension combination caused the issue?
Explore the data and visualization to understand when the issue (possibly a significant number of failures in transactions ) 
happened and which combination of dimension (pmt, pg, bank and sub_type) has the impact.
Tip: Identify the method to detect an anomaly in a metric across 4+ dimensions and apply that method to find the above.


```{r}
setwd("/Users/jacobrichards/Desktop/DS assesment/DS_Exam_2")
transactions <- read.csv(file="transactions(1).csv",header=TRUE)

transactions_original <- transactions
```

add column for failure % of each observation 
```{r}
failure_percent <- numeric(nrow(transactions))
failure_percent <- (1 - transactions[,2]/transactions[,1])*100
transactions$failure_percent <- failure_percent


transactions <- transactions[order(as.POSIXct(transactions[,7], format = "%Y-%m-%d %H")),]
(unique_hours <- unique(transactions[,7]))

percentage_of_failed_transactions_per_hour <- numeric(length(unique_hours))
for (i in 1:72) {
  percentage_of_failed_transactions_per_hour[i] <- ( 1 - sum(transactions[transactions[,7] == unique_hours[i],2])/sum(transactions[transactions[,7] == unique_hours[i],1]))
}


plot(x=seq(1,72,by=1),y=percentage_of_failed_transactions_per_hour,type="o")
abline(v = 70, col = "red", lty = 2) 
abline(v = 20, col = "blue", lty = 2) 
abline(v = 45, col = "green", lty = 2) 

percentage_of_failed_transactions_per_hour[45]
print(order(percentage_of_failed_transactions_per_hour,decreasing = TRUE))

```

we know the highest failure rate over of all transactions over the entire hour is on 


[1] "2020-02-13 20"
[1] "2020-02-13 19"
[1] "2020-02-14 21"
[1] "2020-02-14 20"
[1] "2020-02-13 23"
[1] "2020-02-12 20"

we know what the anomoly is, we know what days it's the highest, so for those days lets look to see if there is a combination of variables 
that they have in common 



highest failure at CONSUMER_FINANCE




the highest failure rate by pg was "not_avaible" which before was a empty element



I have identified that these variables are most highly associated with the peak transaction failure rate. What i need to do now is use a isolated forest model to determine which specific combination of these variables was the most highly associated with transaction failure rate. So i can know what was causing the trans action failure rate in the first place. 

CONSUMER_FINANCE
pg was "not_avaible"
UPI_Collect 





```{r}

transactions$weighted_failure_score <- transactions[,9] * transactions[,1] *100


test_pmt <- as.factor(transactions$pmt)
(levels(test_pmt))

test_pg <- as.factor(transactions$pg)
(levels(test_pg))

(transactions$bank[levels(as.factor(transactions$bank == 304))])

# Convert categorical features to numeric (using dummy encoding or integer encoding)
transactions$pmt <- as.numeric(as.factor(transactions$pmt))
transactions$pg <- as.numeric(as.factor(transactions$pg))
transactions$bank <- as.numeric(as.factor(transactions$bank))
transactions$sub_type <- as.numeric(as.factor(transactions$sub_type))

# Select relevant features for anomaly detection
features <- transactions[, c("weighted_failure_score", "pmt", "pg", "bank", "sub_type")]

# Calculate the Mahalanobis distance for each observation
center <- colMeans(features)
cov_matrix <- cov(features)
mahalanobis_distances <- mahalanobis(features, center, cov_matrix)

# Append Mahalanobis distances to the transactions dataframe
transactions$mahalanobis_score <- mahalanobis_distances

# Determine a threshold for high anomaly scores (e.g., 95th percentile)
threshold <- quantile(mahalanobis_distances, 0.999)
high_mahalanobis_transactions <- transactions[transactions$mahalanobis_score > threshold, ]

# Display the top anomalous transactions
head(high_mahalanobis_transactions, 100)



anamolous <- transactions_original[row.names(high_mahalanobis_transactions),]

anamolous
```


[1] "2020-02-13 20"
[1] "2020-02-13 19"
[1] "2020-02-14 21"
[1] "2020-02-14 20"
[1] "2020-02-13 23"
[1] "2020-02-12 20"






