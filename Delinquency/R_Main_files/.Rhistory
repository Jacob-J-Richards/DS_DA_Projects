knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
fig.width = 6,
fig.height = 4,
dpi = 300,
dev = "png")
train <- read.csv(file="FITB_train.csv",header=TRUE)
setwd("~/Desktop/DS_DA_Projects/Delinquency/R_Main_files")
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
fig.width = 6,
fig.height = 4,
dpi = 300,
dev = "png")
train <- read.csv(file="FITB_train.csv",header=TRUE)
test <- read.csv(file="FITB_test.csv",header=TRUE)
library(ggplot2)
ggplot() + geom_density(data=train, aes(x=feature_3), color="blue") +
geom_density(data=train, aes(x=feature_2), color="red") +
geom_density(data=train, aes(x=feature_1), color="green") +
geom_density(data=train, aes(x=feature_4), color="purple") +
theme_minimal()
library(dplyr)
train$key <- row.names(train)
feature_3_winsor <- data.frame(feature_3 = train$feature_3, key = row.names(train))
feature_3_winsor_clean <- na.omit(feature_3_winsor)
feature_3_winsor_clean <- feature_3_winsor_clean %>%
mutate(z_score = (feature_3 - mean(feature_3)) / sd(feature_3),percentile = ecdf(feature_3)(feature_3) * 100)
feature_3_winsor_df <- feature_3_winsor_clean[!(feature_3_winsor_clean[, 4] < 1 | feature_3_winsor_clean[, 4] > 99), ]
non_matching_keys <- anti_join(train, feature_3_winsor_df, by = "key")$key
train <- train %>% mutate(feature_3 = ifelse(key %in% non_matching_keys, NA, feature_3))
colnames(train)[3] <- "feature_3_winsor"
train[is.na(train[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(train)[3] <- "feature_3_impute"
test[is.na(test[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(test)[3] <- "feature_3_impute"
train$date <- format(as.Date(train$date, format = "%Y-%m-%d"), "%Y")
train <- train %>%
arrange(id, date) %>% # Sort by id and date
group_by(id) %>%
mutate(feature_2 = ifelse(is.na(feature_2),
lead(feature_2, order_by = date), # Try next year
feature_2)) %>%
mutate(feature_2 = ifelse(is.na(feature_2),
lag(feature_2, order_by = date), # Try previous year
feature_2))
colnames(train)[2] <- "feature_2_impute"
test <- test %>%
arrange(id, date) %>%
group_by(id) %>%
mutate(feature_2 = ifelse(is.na(feature_2),
lead(feature_2, order_by = date), # Try next year
feature_2)) %>%
mutate(feature_2 = ifelse(is.na(feature_2),
lag(feature_2, order_by = date), # Try previous year
feature_2))
colnames(test)[2] <- "feature_2_impute"
train <- na.omit(train)
test <- na.omit(test)
library(dplyr)
train <- train %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
colnames(train) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y","key")
test <- test %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
colnames(test) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y")
ggplot() + geom_density(data=train, aes(x=feature_3_standard), color="blue") +
geom_density(data=train, aes(x=feature_2_standard), color="red") +
geom_density(data=train, aes(x=feature_1_standard), color="green") +
geom_density(data=train, aes(x=feature_4_standard), color="purple") +
theme_minimal()
library(nnet)
train$y <- as.numeric(as.character(factor(train$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
#This is necessary so that the delinquent value is recognized as the positive outcome.
delinquency_model <- multinom(y ~ feature_1_standard + feature_2_standard + feature_3_standard + feature_4_standard,
data=train,family=binomial())
summary(delinquency_model)
library(pROC)
test$predicted_y <- predict(delinquency_model, newdata = test, type = "class")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
test$Probability <- predict(delinquency_model, newdata = test, type = "probs")
options(digits = 4)
roc_curve <- roc(response = test$y_numeric, predictor = test$Probability)
roc_metrics <- coords(roc_curve, x = "all", ret = c("threshold", "sensitivity", "specificity"))
(head(roc_metrics,5))
auc_value <- auc(roc_curve)
optimal_threshold <- roc_metrics$threshold[which.min(abs(roc_metrics$sensitivity - roc_metrics$specificity))]
roc_metrics$threshold <- as.numeric(roc_metrics$threshold)
roc_data <- data.frame(
TPR = rev(roc_curve$sensitivities),
FPR = rev(1 - roc_curve$specificities)
)
auc_value <- auc(roc_curve)
ggplot(roc_data, aes(x = FPR, y = TPR)) +
geom_smooth(color = "blue", size = 1) +
geom_abline(linetype = "dashed", color = "gray") +
labs(
title = "ROC Curve for Multinomial Logistic Regression",
x = "False Positive Rate (1 - Specificity)",
y = "True Positive Rate (Sensitivity)",
caption = paste("AUC:", round(auc_value, 4))
) +
coord_fixed() +  # Maintain proportional scales
xlim(-0.5, 1.5) +  # Expand x-axis
theme_minimal() +
theme(plot.caption = element_text(hjust = 0.5, size = 12))
ggplot(roc_metrics, aes(x = threshold)) +
geom_smooth(aes(y = sensitivity, color = "Sensitivity")) +
geom_smooth(aes(y = specificity, color = "Specificity")) +
labs(title = "Sensitivity and Specificity vs. Threshold",
x = "Threshold", y = "Metric Value") +
scale_color_manual(name = "Metrics", values = c("Sensitivity" = "red", "Specificity" = "blue")) +
theme_minimal()
test$predicted_class <- ifelse(test$Probability >= roc_metrics$threshold[which.min(abs(roc_metrics$sensitivity - roc_metrics$specificity))], 1, 0)
library(caret)
conf_matrix <- confusionMatrix(
factor(test$predicted_class, levels = c(0, 1)),
factor(test$y_numeric, levels = c(0, 1)))
confusion_table <- as.data.frame.matrix(conf_matrix$table)
rownames(confusion_table) <- c("Actual: Non-delinquent", "Actual: Delinquent")
colnames(confusion_table) <- c("Predicted: Non-delinquent", "Predicted: Delinquent")
print("Confusion Matrix:")
print(confusion_table)
true_positives <- confusion_table[2, 2]
false_positives <- confusion_table[1, 2]
true_negatives <- confusion_table[1, 1]
false_negatives <- confusion_table[2, 1]
library(car)
X <- model.matrix(~ feature_1_standard + feature_2_standard + feature_3_standard + feature_4_standard, data=train)
vif_values <- diag(solve(cor(X[, -1])))
names(vif_values) <- colnames(X)[-1]
print(vif_values)
library(corrplot)
cor_matrix <- cor(train[, c("feature_1_standard", "feature_2_standard", "feature_3_standard", "feature_4_standard")])
corrplot(cor_matrix,
method = "color",
col = colorRampPalette(c("white", "red"))(200),
type = "upper",
tl.col = "black",
tl.srt = 45,
addCoef.col = "black",
number.cex = 0.8)
full_model <- glm(y ~ feature_1_standard + feature_2_standard + feature_3_standard + feature_4_standard, data = train, family = binomial())
model_without_feature_1 <- glm(y ~ feature_2_standard + feature_3_standard + feature_4_standard, data = train, family = binomial())
model_without_feature_3 <- glm(y ~ feature_1_standard + feature_2_standard + feature_4_standard, data = train, family = binomial())
anova(model_without_feature_1, full_model, test = "LRT")
anova(model_without_feature_3, full_model, test = "LRT")
library(pROC)
library(ggplot2)
model_without_feature_1 <- glm(y ~ feature_2_standard + feature_3_standard + feature_4_standard,
data = train, family = binomial())
test_no_feature_1 <- test %>%
select(-feature_1_standard)
test_no_feature_1$Probability <- predict(model_without_feature_1, newdata = test_no_feature_1, type = "response")
test_no_feature_1$y_numeric <- as.numeric(as.character(factor(test_no_feature_1$y,
levels = c("90+DPD", "active"),
labels = c(1, 0))))
roc_curve <- roc(response = test_no_feature_1$y_numeric,
predictor = test_no_feature_1$Probability)
roc_metrics <- coords(roc_curve, x = "all", ret = c("threshold", "sensitivity", "specificity"))
# Extract data for ROC curve
roc_data <- data.frame(
TPR = rev(roc_curve$sensitivities),  # True Positive Rate (Sensitivity)
FPR = rev(1 - roc_curve$specificities)  # False Positive Rate (1 - Specificity)
)
# Calculate AUC value
auc_value <- auc(roc_curve)
# Create the ROC curve plot using ggplot2
ggplot(roc_data, aes(x = FPR, y = TPR)) +
geom_smooth(color = "blue", size = 1) +
geom_abline(linetype = "dashed", color = "gray") +  # Diagonal line for random chance
labs(
title = "ROC Curve Without Feature 3",
x = "False Positive Rate (1 - Specificity)",
y = "True Positive Rate (Sensitivity)",
caption = paste("AUC:", round(auc_value, 4))
) +
coord_fixed() +  # Maintain proportional scales
xlim(-0.5, 1.5) +  # Expand x-axis for better visualization
theme_minimal() +
theme(plot.caption = element_text(hjust = 0.5, size = 12))
roc_metrics_df <- as.data.frame(roc_metrics)
ggplot(roc_metrics_df, aes(x = threshold)) +
geom_smooth(aes(y = sensitivity, color = "Sensitivity")) +
geom_smooth(aes(y = specificity, color = "Specificity")) +
labs(title = "Sensitivity and Specificity vs. Threshold Without Feature 1",
x = "Threshold", y = "Metric Value") +
scale_color_manual(name = "Metrics", values = c("Sensitivity" = "red", "Specificity" = "blue")) +
theme_minimal()
library(pROC)
library(ggplot2)
model_without_feature_3 <- glm(y ~ feature_1_standard + feature_2_standard + feature_4_standard,
data = train, family = binomial())
test_no_feature_3 <- test %>%
select(-feature_3_standard)
test_no_feature_3$Probability <- predict(model_without_feature_3, newdata = test_no_feature_3, type = "response")
test_no_feature_3$y_numeric <- as.numeric(as.character(factor(test_no_feature_3$y,
levels = c("90+DPD", "active"),
labels = c(1, 0))))
roc_curve <- roc(response = test_no_feature_3$y_numeric,
predictor = test_no_feature_3$Probability)
roc_metrics <- coords(roc_curve, x = "all", ret = c("threshold", "sensitivity", "specificity"))
# Extract data for ROC curve
roc_data <- data.frame(
TPR = rev(roc_curve$sensitivities),  # True Positive Rate (Sensitivity)
FPR = rev(1 - roc_curve$specificities)  # False Positive Rate (1 - Specificity)
)
# Calculate AUC value
auc_value <- auc(roc_curve)
# Create the ROC curve plot using ggplot2
ggplot(roc_data, aes(x = FPR, y = TPR)) +
geom_smooth(color = "blue", size = 1) +
geom_abline(linetype = "dashed", color = "gray") +  # Diagonal line for random chance
labs(
title = "ROC Curve Without Feature 3",
x = "False Positive Rate (1 - Specificity)",
y = "True Positive Rate (Sensitivity)",
caption = paste("AUC:", round(auc_value, 4))
) +
coord_fixed() +  # Maintain proportional scales
xlim(-0.5, 1.5) +  # Expand x-axis for better visualization
theme_minimal() +
theme(plot.caption = element_text(hjust = 0.5, size = 12))
roc_metrics_df <- as.data.frame(roc_metrics)
ggplot(roc_metrics_df, aes(x = threshold)) +
geom_smooth(aes(y = sensitivity, color = "Sensitivity")) +
geom_smooth(aes(y = specificity, color = "Specificity")) +
labs(title = "Sensitivity and Specificity vs. Threshold Without Feature 3",
x = "Threshold", y = "Metric Value") +
scale_color_manual(name = "Metrics", values = c("Sensitivity" = "red", "Specificity" = "blue")) +
theme_minimal()
