test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
test
#positive_class_probs <- test$predicted_probs[,"90+DPD"]
model <- multinom(y ~ feature_1_standard + feature_2_standard + feature_3_standard + feature_4_standard, data=train,family=binomial())
library(tidyverse)
train <- read.csv(file="FITB_train.csv",header=TRUE)
test <- read.csv(file="FITB_test.csv",header=TRUE)
train_unmodified <- train
library(ggplot2)
ggplot(data=train,aes(feature_3)) + geom_density()
ggplot(data=test,aes(feature_3)) + geom_density()
train$key <- row.names(train)
feature_3_winsor <- data.frame(feature_3 = train$feature_3, key = row.names(train))
feature_3_winsor_clean <- na.omit(feature_3_winsor)
feature_3_winsor_clean <- feature_3_winsor_clean %>%
mutate(z_score = (feature_3 - mean(feature_3)) / sd(feature_3),percentile = ecdf(feature_3)(feature_3) * 100)
feature_3_winsor_df <- feature_3_winsor_clean[!(feature_3_winsor_clean[, 4] < 1 | feature_3_winsor_clean[, 4] > 99), ]
non_matching_keys <- anti_join(train, feature_3_winsor_df, by = "key")$key
train <- train %>% mutate(feature_3 = ifelse(key %in% non_matching_keys, NA, feature_3))
colnames(train)[3] <- "feature_3_winsor"
ggplot(data=train,aes(feature_3_winsor)) + geom_density()
train[is.na(train[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(train)[3] <- "feature_3_impute"
test[is.na(test[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(test)[3] <- "feature_3_impute"
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),1]
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),3]
train$feature_2 <- train_unmodified$feature_2
colnames(train)[2] <- "feature_2_impute"
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),1]
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),3]
test$feature_2 <- test$feature_2
colnames(test)[2] <- "feature_2_impute"
train
(colnames(train))
library(ggplot2)
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
train
library(dplyr)
train <- train %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
train
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
colnames(train) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y","key")
test <- test %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
ggplot(data=test,aes(x=feature_1)) + geom_density() + geom_density(data=test,aes(x=feature_2_impute)) + geom_density(data=test,aes(x=feature_3_impute))
colnames(test) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y")
train
library(nnet)
model <- multinom(y ~ feature_1_standard + feature_2_standard + feature_3_standard + feature_4_standard, data=train,family=binomial())
summary(model)
test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
test
#positive_class_probs <- test[test$y == "90+DPD,]
library(tidyverse)
train <- read.csv(file="FITB_train.csv",header=TRUE)
test <- read.csv(file="FITB_test.csv",header=TRUE)
train_unmodified <- train
library(ggplot2)
ggplot(data=train,aes(feature_3)) + geom_density()
ggplot(data=test,aes(feature_3)) + geom_density()
train$key <- row.names(train)
feature_3_winsor <- data.frame(feature_3 = train$feature_3, key = row.names(train))
feature_3_winsor_clean <- na.omit(feature_3_winsor)
feature_3_winsor_clean <- feature_3_winsor_clean %>%
mutate(z_score = (feature_3 - mean(feature_3)) / sd(feature_3),percentile = ecdf(feature_3)(feature_3) * 100)
feature_3_winsor_df <- feature_3_winsor_clean[!(feature_3_winsor_clean[, 4] < 1 | feature_3_winsor_clean[, 4] > 99), ]
non_matching_keys <- anti_join(train, feature_3_winsor_df, by = "key")$key
train <- train %>% mutate(feature_3 = ifelse(key %in% non_matching_keys, NA, feature_3))
colnames(train)[3] <- "feature_3_winsor"
ggplot(data=train,aes(feature_3_winsor)) + geom_density()
train[is.na(train[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(train)[3] <- "feature_3_impute"
test[is.na(test[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(test)[3] <- "feature_3_impute"
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),1]
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),3]
train$feature_2 <- train_unmodified$feature_2
colnames(train)[2] <- "feature_2_impute"
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),1]
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),3]
test$feature_2 <- test$feature_2
colnames(test)[2] <- "feature_2_impute"
train
(colnames(train))
library(ggplot2)
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
train
library(dplyr)
train <- train %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
train
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
colnames(train) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y","key")
test <- test %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
ggplot(data=test,aes(x=feature_1)) + geom_density() + geom_density(data=test,aes(x=feature_2_impute)) + geom_density(data=test,aes(x=feature_3_impute))
colnames(test) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y")
train
library(nnet)
model <- multinom(y ~ feature_1_standard + feature_2_standard + feature_3_standard + feature_4_standard, data=train,family=binomial())
summary(model)
test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
test
positive_class_probs <- test[test$y == "90+ DPD",9]
library(tidyverse)
train <- read.csv(file="FITB_train.csv",header=TRUE)
test <- read.csv(file="FITB_test.csv",header=TRUE)
train_unmodified <- train
library(ggplot2)
ggplot(data=train,aes(feature_3)) + geom_density()
ggplot(data=test,aes(feature_3)) + geom_density()
train$key <- row.names(train)
feature_3_winsor <- data.frame(feature_3 = train$feature_3, key = row.names(train))
feature_3_winsor_clean <- na.omit(feature_3_winsor)
feature_3_winsor_clean <- feature_3_winsor_clean %>%
mutate(z_score = (feature_3 - mean(feature_3)) / sd(feature_3),percentile = ecdf(feature_3)(feature_3) * 100)
feature_3_winsor_df <- feature_3_winsor_clean[!(feature_3_winsor_clean[, 4] < 1 | feature_3_winsor_clean[, 4] > 99), ]
non_matching_keys <- anti_join(train, feature_3_winsor_df, by = "key")$key
train <- train %>% mutate(feature_3 = ifelse(key %in% non_matching_keys, NA, feature_3))
colnames(train)[3] <- "feature_3_winsor"
ggplot(data=train,aes(feature_3_winsor)) + geom_density()
train[is.na(train[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(train)[3] <- "feature_3_impute"
test[is.na(test[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(test)[3] <- "feature_3_impute"
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),1]
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),3]
train$feature_2 <- train_unmodified$feature_2
colnames(train)[2] <- "feature_2_impute"
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),1]
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),3]
test$feature_2 <- test$feature_2
colnames(test)[2] <- "feature_2_impute"
train
(colnames(train))
library(ggplot2)
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
train
library(dplyr)
train <- train %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
train
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
colnames(train) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y","key")
test <- test %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
ggplot(data=test,aes(x=feature_1)) + geom_density() + geom_density(data=test,aes(x=feature_2_impute)) + geom_density(data=test,aes(x=feature_3_impute))
colnames(test) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y")
train
library(nnet)
model <- multinom(y ~ feature_1_standard + feature_2_standard + feature_3_standard + feature_4_standard, data=train,family=binomial())
summary(model)
test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
test
positive_class_probs <- test[test$y == "90+ DPD",9]
positive_class_probs
test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
test
positive_class_probs <- test[test[,7] == "90+ DPD",9]
positive_class_probs
test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
test
positive_class_probs <- test[test[,7] == "90+DPD",9]
positive_class_probs
test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
test
positive_class_probs <- test[test$y == "90+DPD",test$predicted_probs]
positive_class_probs
library(tidyverse)
train <- read.csv(file="FITB_train.csv",header=TRUE)
test <- read.csv(file="FITB_test.csv",header=TRUE)
train_unmodified <- train
library(ggplot2)
ggplot(data=train,aes(feature_3)) + geom_density()
ggplot(data=test,aes(feature_3)) + geom_density()
train$key <- row.names(train)
feature_3_winsor <- data.frame(feature_3 = train$feature_3, key = row.names(train))
feature_3_winsor_clean <- na.omit(feature_3_winsor)
feature_3_winsor_clean <- feature_3_winsor_clean %>%
mutate(z_score = (feature_3 - mean(feature_3)) / sd(feature_3),percentile = ecdf(feature_3)(feature_3) * 100)
feature_3_winsor_df <- feature_3_winsor_clean[!(feature_3_winsor_clean[, 4] < 1 | feature_3_winsor_clean[, 4] > 99), ]
non_matching_keys <- anti_join(train, feature_3_winsor_df, by = "key")$key
train <- train %>% mutate(feature_3 = ifelse(key %in% non_matching_keys, NA, feature_3))
colnames(train)[3] <- "feature_3_winsor"
ggplot(data=train,aes(feature_3_winsor)) + geom_density()
train[is.na(train[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(train)[3] <- "feature_3_impute"
test[is.na(test[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(test)[3] <- "feature_3_impute"
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),1]
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),3]
train$feature_2 <- train_unmodified$feature_2
colnames(train)[2] <- "feature_2_impute"
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),1]
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),3]
test$feature_2 <- test$feature_2
colnames(test)[2] <- "feature_2_impute"
train
(colnames(train))
library(ggplot2)
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
train
library(dplyr)
train <- train %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
train
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
colnames(train) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y","key")
test <- test %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
ggplot(data=test,aes(x=feature_1)) + geom_density() + geom_density(data=test,aes(x=feature_2_impute)) + geom_density(data=test,aes(x=feature_3_impute))
colnames(test) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y")
train
library(nnet)
model <- multinom(y ~ feature_1_standard + feature_2_standard + feature_3_standard + feature_4_standard, data=train,family=binomial())
summary(model)
test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
test
positive_class_probs <- test[test$y == "90+DPD",9]
positive_class_probs
library(tidyverse)
train <- read.csv(file="FITB_train.csv",header=TRUE)
test <- read.csv(file="FITB_test.csv",header=TRUE)
train_unmodified <- train
library(ggplot2)
ggplot(data=train,aes(feature_3)) + geom_density()
ggplot(data=test,aes(feature_3)) + geom_density()
train$key <- row.names(train)
feature_3_winsor <- data.frame(feature_3 = train$feature_3, key = row.names(train))
feature_3_winsor_clean <- na.omit(feature_3_winsor)
feature_3_winsor_clean <- feature_3_winsor_clean %>%
mutate(z_score = (feature_3 - mean(feature_3)) / sd(feature_3),percentile = ecdf(feature_3)(feature_3) * 100)
feature_3_winsor_df <- feature_3_winsor_clean[!(feature_3_winsor_clean[, 4] < 1 | feature_3_winsor_clean[, 4] > 99), ]
non_matching_keys <- anti_join(train, feature_3_winsor_df, by = "key")$key
train <- train %>% mutate(feature_3 = ifelse(key %in% non_matching_keys, NA, feature_3))
colnames(train)[3] <- "feature_3_winsor"
ggplot(data=train,aes(feature_3_winsor)) + geom_density()
train[is.na(train[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(train)[3] <- "feature_3_impute"
test[is.na(test[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(test)[3] <- "feature_3_impute"
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),1]
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),3]
train$feature_2 <- train_unmodified$feature_2
colnames(train)[2] <- "feature_2_impute"
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),1]
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),3]
test$feature_2 <- test$feature_2
colnames(test)[2] <- "feature_2_impute"
train
(colnames(train))
library(ggplot2)
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
train
library(dplyr)
train <- train %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
train
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
colnames(train) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y","key")
test <- test %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
ggplot(data=test,aes(x=feature_1)) + geom_density() + geom_density(data=test,aes(x=feature_2_impute)) + geom_density(data=test,aes(x=feature_3_impute))
colnames(test) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y")
train
library(nnet)
model <- multinom(y ~ feature_1_standard + feature_2_standard + feature_3_standard + feature_4_standard, data=train,family=binomial())
summary(model)
# Install and load the pROC package if not already installed
if (!require("pROC")) install.packages("pROC")
library(pROC)
# Predict probabilities for the test data
test$predicted_probs <- predict(model, newdata = test, type = "probs")
# Ensure the response variable is numeric (1 for "90+DPD", 0 for "active")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
# Extract probabilities for the positive class ("90+DPD")
positive_class_probs <- test$predicted_probs[, "90+DPD"]
library(pROC)
library(tidyverse)
train <- read.csv(file="FITB_train.csv",header=TRUE)
test <- read.csv(file="FITB_test.csv",header=TRUE)
train_unmodified <- train
library(ggplot2)
ggplot(data=train,aes(feature_3)) + geom_density()
ggplot(data=test,aes(feature_3)) + geom_density()
train$key <- row.names(train)
feature_3_winsor <- data.frame(feature_3 = train$feature_3, key = row.names(train))
feature_3_winsor_clean <- na.omit(feature_3_winsor)
feature_3_winsor_clean <- feature_3_winsor_clean %>%
mutate(z_score = (feature_3 - mean(feature_3)) / sd(feature_3),percentile = ecdf(feature_3)(feature_3) * 100)
feature_3_winsor_df <- feature_3_winsor_clean[!(feature_3_winsor_clean[, 4] < 1 | feature_3_winsor_clean[, 4] > 99), ]
non_matching_keys <- anti_join(train, feature_3_winsor_df, by = "key")$key
train <- train %>% mutate(feature_3 = ifelse(key %in% non_matching_keys, NA, feature_3))
colnames(train)[3] <- "feature_3_winsor"
ggplot(data=train,aes(feature_3_winsor)) + geom_density()
train[is.na(train[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(train)[3] <- "feature_3_impute"
test[is.na(test[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(test)[3] <- "feature_3_impute"
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),1]
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),3]
train$feature_2 <- train_unmodified$feature_2
colnames(train)[2] <- "feature_2_impute"
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),1]
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),3]
test$feature_2 <- test$feature_2
colnames(test)[2] <- "feature_2_impute"
train
(colnames(train))
library(ggplot2)
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
train
library(dplyr)
train <- train %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
train
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
colnames(train) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y","key")
test <- test %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
ggplot(data=test,aes(x=feature_1)) + geom_density() + geom_density(data=test,aes(x=feature_2_impute)) + geom_density(data=test,aes(x=feature_3_impute))
colnames(test) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y")
train
library(nnet)
model <- multinom(y ~ feature_1_standard + feature_2_standard + feature_3_standard + feature_4_standard, data=train,family=binomial())
summary(model)
test
test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
# Install and load the pROC package if not already installed
library(pROC)
test
test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
# Install and load the pROC package if not already installed
library(pROC)
test
positive_class_probs <- test$predicted_probs[test$y == "90+DPD"]
# Compute the ROC curve
roc_curve <- roc(test$y_numeric, positive_class_probs)
library(pROC)
test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
test
roc_curve <- roc(response = test$y_numeric, predictor = test$predicted_probs)
plot(roc_curve, main = "ROC Curve for Multinomial Logistic Regression", col = "blue", lwd = 2)
# Print the AUC
auc_value <- auc(roc_curve)
print(paste("AUC:", auc_value))
library(pROC)
test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
roc_curve <- roc(response = test$y_numeric, predictor = test$predicted_probs)
plot(roc_curve, main = "ROC Curve for Multinomial Logistic Regression", col = "blue", lwd = 2)
print(paste("AUC:", auc(roc_curve)))
roc_curve
library(tidyverse)
train <- read.csv(file="FITB_train.csv",header=TRUE)
test <- read.csv(file="FITB_test.csv",header=TRUE)
train_unmodified <- train
library(ggplot2)
ggplot(data=train,aes(feature_3)) + geom_density()
ggplot(data=test,aes(feature_3)) + geom_density()
train$key <- row.names(train)
feature_3_winsor <- data.frame(feature_3 = train$feature_3, key = row.names(train))
feature_3_winsor_clean <- na.omit(feature_3_winsor)
feature_3_winsor_clean <- feature_3_winsor_clean %>%
mutate(z_score = (feature_3 - mean(feature_3)) / sd(feature_3),percentile = ecdf(feature_3)(feature_3) * 100)
feature_3_winsor_df <- feature_3_winsor_clean[!(feature_3_winsor_clean[, 4] < 1 | feature_3_winsor_clean[, 4] > 99), ]
non_matching_keys <- anti_join(train, feature_3_winsor_df, by = "key")$key
train <- train %>% mutate(feature_3 = ifelse(key %in% non_matching_keys, NA, feature_3))
colnames(train)[3] <- "feature_3_winsor"
ggplot(data=train,aes(feature_3_winsor)) + geom_density()
train[is.na(train[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(train)[3] <- "feature_3_impute"
test[is.na(test[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(test)[3] <- "feature_3_impute"
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),1]
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),3]
train$feature_2 <- train_unmodified$feature_2
colnames(train)[2] <- "feature_2_impute"
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),1]
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),3]
test$feature_2 <- test$feature_2
colnames(test)[2] <- "feature_2_impute"
train
(colnames(train))
library(ggplot2)
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
train
library(dplyr)
train <- train %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
train
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
colnames(train) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y","key")
test <- test %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
ggplot(data=test,aes(x=feature_1)) + geom_density() + geom_density(data=test,aes(x=feature_2_impute)) + geom_density(data=test,aes(x=feature_3_impute))
colnames(test) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y")
train
library(nnet)
model <- multinom(y ~ feature_1_standard + feature_2_standard + feature_3_standard + feature_4_standard, data=train,family=binomial())
summary(model)
library(pROC)
test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
roc_curve <- roc(response = test$y_numeric, predictor = test$predicted_probs)
plot(roc_curve, main = "ROC Curve for Multinomial Logistic Regression", col = "blue", lwd = 2)
print(paste("AUC:", auc(roc_curve)))
library(tidyverse)
train <- read.csv(file="FITB_train.csv",header=TRUE)
test <- read.csv(file="FITB_test.csv",header=TRUE)
train_unmodified <- train
library(ggplot2)
ggplot(data=train,aes(feature_3)) + geom_density()
ggplot(data=test,aes(feature_3)) + geom_density()
train$key <- row.names(train)
feature_3_winsor <- data.frame(feature_3 = train$feature_3, key = row.names(train))
feature_3_winsor_clean <- na.omit(feature_3_winsor)
feature_3_winsor_clean <- feature_3_winsor_clean %>%
mutate(z_score = (feature_3 - mean(feature_3)) / sd(feature_3),percentile = ecdf(feature_3)(feature_3) * 100)
feature_3_winsor_df <- feature_3_winsor_clean[!(feature_3_winsor_clean[, 4] < 1 | feature_3_winsor_clean[, 4] > 99), ]
non_matching_keys <- anti_join(train, feature_3_winsor_df, by = "key")$key
train <- train %>% mutate(feature_3 = ifelse(key %in% non_matching_keys, NA, feature_3))
colnames(train)[3] <- "feature_3_winsor"
ggplot(data=train,aes(feature_3_winsor)) + geom_density()
train[is.na(train[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(train)[3] <- "feature_3_impute"
test[is.na(test[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(test)[3] <- "feature_3_impute"
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),1]
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),3]
train$feature_2 <- train_unmodified$feature_2
colnames(train)[2] <- "feature_2_impute"
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),1]
test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),3]
test$feature_2 <- test$feature_2
colnames(test)[2] <- "feature_2_impute"
train
(colnames(train))
library(ggplot2)
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
train
library(dplyr)
train <- train %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
train
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
colnames(train) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y","key")
test <- test %>%
mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4),
~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
ggplot(data=test,aes(x=feature_1)) + geom_density() + geom_density(data=test,aes(x=feature_2_impute)) + geom_density(data=test,aes(x=feature_3_impute))
colnames(test) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y")
train
library(nnet)
model <- multinom(y ~ feature_1_standard + feature_2_standard + feature_3_standard + feature_4_standard, data=train,family=binomial())
summary(model)
library(pROC)
test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
roc_curve <- roc(response = test$y_numeric, predictor = test$predicted_probs)
plot(roc_curve, main = "ROC Curve for Multinomial Logistic Regression", col = "blue", lwd = 2)
print(paste("AUC:", auc(roc_curve)))
library(pROC)
test$predicted_y <- predict(model, newdata = test, type = "class")
test$predicted_probs <- predict(model, newdata = test, type = "probs")
test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
test
roc_curve <- roc(response = test$y_numeric, predictor = test$predicted_probs)
plot(roc_curve, main = "ROC Curve for Multinomial Logistic Regression", col = "blue", lwd = 2)
print(paste("AUC:", auc(roc_curve)))
