---
title: "Untitled"
output: html_document
date: "2024-11-23"
---

# Instruction

The panel dataset contains commercial customers' financial information and days past due indicator from 2000 to 2020. The goal is to build a binary classifier to predict customers 90+ days past due **(90+DPD)** probability.



```{r}
library(tidyverse)
train <- read.csv(file="FITB_train.csv",header=TRUE)
test <- read.csv(file="FITB_test.csv",header=TRUE)
```

2.  Winsorize **"feature_3"** by limiting the extreme values to 1 percentile (left tail) and 99 percentile (right tail) on the training set. Name it **"feature_3_winsor"**. Make appropriate treatments on the testing set.

```{r}
library(ggplot2)
ggplot(data=train,aes(feature_3)) + geom_density()
ggplot(data=test,aes(feature_3)) + geom_density()
```

Clearly this is a problem. Let's cut out the 1% tails on both ends on the training set. Leaving the test data alone since we want to see how the model does on sub-optimal inputs. 

```{r}
train$key <- row.names(train)
feature_3_winsor <- data.frame(feature_3 = train$feature_3, key = row.names(train))
feature_3_winsor_clean <- na.omit(feature_3_winsor)

feature_3_winsor_clean <- feature_3_winsor_clean %>%
  mutate(z_score = (feature_3 - mean(feature_3)) / sd(feature_3),percentile = ecdf(feature_3)(feature_3) * 100)

feature_3_winsor_df <- feature_3_winsor_clean[!(feature_3_winsor_clean[, 4] < 1 | feature_3_winsor_clean[, 4] > 99), ]

non_matching_keys <- anti_join(train, feature_3_winsor_df, by = "key")$key

train <- train %>% mutate(feature_3 = ifelse(key %in% non_matching_keys, NA, feature_3))

colnames(train)[3] <- "feature_3_winsor"
```

```{r}
ggplot(data=train,aes(feature_3_winsor)) + geom_density()
```



3.  Identify missing values for **"feature_3_winsor"**. Then, impute the missings with median value on the training set. Name the new feature **"feature_3_impute"**. Make appropriate treatments on the testing set.


This time i will impute the median into the testing data as well.  
```{r}
train[is.na(train[,3]),3] <- median(feature_3_winsor_clean$feature_3)

colnames(train)[3] <- "feature_3_impute"

test[is.na(test[,3]),3] <- median(feature_3_winsor_clean$feature_3)
```


4.  Identify missing values for **"feature_2"**. Then, for each **"id"**, impute the missings with the value from previous year, if not available, use the value from next year. Name the new feature **"feature_2_impute"**. Make appropriate treatments on the testing set.



```{r}

```

5.  Standardize **"feature_1"**, **"feature_2_impute"**, **"feature_3_impute"**, **"feature_4"** for the training set. Make appropriate treatments on the testing set. Name the features **"feature_1_standard"**, **"feature_2_standard"**, **"feature_3_standard"**, **"feature_4_standard"**

6.  Build a logistic regression on the training set to predict **'y'** being **(90+DPD)** using **"feature_1_standard"**, **"feature_2_standard"**, **"feature_3_standard"**, **"feature_4_standard"** as independent variables.

7.  Report AUC on the **testing set**.

8.  Report confusion matrix on the **testing set**.

9.  Identify multicollinearity in the model.

10. Load both training and testing sets.

