---
title: "Untitled"
output: html_document
date: "2024-11-23"
---

# Instruction

The panel dataset contains commercial customers' financial information and days past due indicator from 2000 to 2020. The goal is to build a binary classifier to predict customers 90+ days past due **(90+DPD)** probability.

3.  Identify missing values for **"feature_3_winsor"**. Then, impute the missings with median value on the training set. Name the new feature **"feature_3_impute"**. Make appropriate treatments on the testing set.

4.  Identify missing values for **"feature_2"**. Then, for each **"id"**, impute the missings with the value from previous year, if not available, use the value from next year. Name the new feature **"feature_2_impute"**. Make appropriate treatments on the testing set.

5.  Standardize **"feature_1"**, **"feature_2_impute"**, **"feature_3_impute"**, **"feature_4"** for the training set. Make appropriate treatments on the testing set. Name the features **"feature_1_standard"**, **"feature_2_standard"**, **"feature_3_standard"**, **"feature_4_standard"**

6.  Build a logistic regression on the training set to predict **'y'** being **(90+DPD)** using **"feature_1_standard"**, **"feature_2_standard"**, **"feature_3_standard"**, **"feature_4_standard"** as independent variables.

7.  Report AUC on the **testing set**.

8.  Report confusion matrix on the **testing set**.

9.  Identify multicollinearity in the model.

10. Load both training and testing sets.

```{r}
train <- read.csv(file="FITB_train.csv",header=TRUE)
test <- read.csv(file="FITB_test.csv",header=TRUE)
```

2.  Winsorize **"feature_3"** by limiting the extreme values to 1 percentile (left tail) and 99 percentile (right tail) on the training set. Name it **"feature_3_winsor"**. Make appropriate treatments on the testing set.

```{r}
ggplot(data=train,aes(feature_3)) + geom_density()
```

Clearly this is a problem. Let's cut out the 1% tails on both ends.

```{r}
feature_3_winsor <- data.frame(feature_3 = train$feature_3)
feature_3_winsor$row_names <- row.names(train)
feature_3_winsor_clean <- na.omit(feature_3_winsor)

feature_3_winsor_clean

feature_3_winsor_clean %>%
  mutate(z_score = (feature_3 - mean(feature_3)) / sd(feature_3),percentile = ecdf(feature_3)(feature_3) * 100)


```








