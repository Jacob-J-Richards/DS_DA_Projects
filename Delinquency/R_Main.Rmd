---
title: "Untitled"
output: html_document
date: "2024-11-23"
---

# Instruction

The panel data-set contains commercial customers' financial information and days past due indicator from 2000 to 2020. The goal is to build a binary classifier to predict customers 90+ days past due **(90+DPD)** probability.

```{r}
library(tidyverse)
train <- read.csv(file="FITB_train.csv",header=TRUE)
test <- read.csv(file="FITB_test.csv",header=TRUE)
train_unmodified <- train
```

2.  Winsorize **"feature_3"** by limiting the extreme values to 1 percentile (left tail) and 99 percentile (right tail) on the training set. Name it **"feature_3_winsor"**. Make appropriate treatments on the testing set.

```{r}
library(ggplot2)
ggplot(data=train,aes(feature_3)) + geom_density()
ggplot(data=test,aes(feature_3)) + geom_density()
```

Clearly this is a problem. Let's cut out the 1% tails on both ends on the training set. Leaving the test data alone since we want to see how the model does on sub-optimal inputs.

```{r}
train$key <- row.names(train)
feature_3_winsor <- data.frame(feature_3 = train$feature_3, key = row.names(train))
feature_3_winsor_clean <- na.omit(feature_3_winsor)

feature_3_winsor_clean <- feature_3_winsor_clean %>%
  mutate(z_score = (feature_3 - mean(feature_3)) / sd(feature_3),percentile = ecdf(feature_3)(feature_3) * 100)

feature_3_winsor_df <- feature_3_winsor_clean[!(feature_3_winsor_clean[, 4] < 1 | feature_3_winsor_clean[, 4] > 99), ]

non_matching_keys <- anti_join(train, feature_3_winsor_df, by = "key")$key

train <- train %>% mutate(feature_3 = ifelse(key %in% non_matching_keys, NA, feature_3))

colnames(train)[3] <- "feature_3_winsor"
```

```{r}
ggplot(data=train,aes(feature_3_winsor)) + geom_density()
```

3.  Identify missing values for **"feature_3_winsor"**. Then, impute the missings with median value on the training set. Name the new feature **"feature_3_impute"**. Make appropriate treatments on the testing set.

This time i will impute the median into the testing data as well.

```{r}
train[is.na(train[,3]),3] <- median(feature_3_winsor_clean$feature_3)

colnames(train)[3] <- "feature_3_impute"

test[is.na(test[,3]),3] <- median(feature_3_winsor_clean$feature_3)
colnames(test)[3] <- "feature_3_impute"
```

4.  Identify missing values for **"feature_2"**. Then, for each **"id"**, impute the missings with the value from previous year, if not available, use the value from next year. Name the new feature **"feature_2_impute"**. Make appropriate treatments on the testing set.

This time will do the same thing for training and testing data

```{r}
train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),1]

train_unmodified[is.na(train_unmodified[,2]) , 2] <- train_unmodified[is.na(train_unmodified[,2]),3]

train$feature_2 <- train_unmodified$feature_2

colnames(train)[2] <- "feature_2_impute"




test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),1]

test[is.na(test[,2]) , 2] <- test[is.na(test[,2]),3]

test$feature_2 <- test$feature_2

colnames(test)[2] <- "feature_2_impute"
train
(colnames(train))
```

5.  Standardize **"feature_1"**, **"feature_2_impute"**, **"feature_3_impute"**, **"feature_4"** for the training set. Make appropriate treatments on the testing set. Name the features **"feature_1_standard"**, **"feature_2_standard"**, **"feature_3_standard"**, **"feature_4_standard"**

standardize by z-score for both testing and training

```{r}
library(ggplot2)
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))
train
```

```{r}
library(dplyr)
train <- train %>%
  mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4), 
                ~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))
train
ggplot(data=train,aes(x=feature_1)) + geom_density() + geom_density(data=train,aes(x=feature_2_impute)) + geom_density(data=train,aes(x=feature_3_impute))

colnames(train) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y","key")


test <- test %>%
  mutate(across(c(feature_1, feature_2_impute, feature_3_impute, feature_4), 
                ~ (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)))

ggplot(data=test,aes(x=feature_1)) + geom_density() + geom_density(data=test,aes(x=feature_2_impute)) + geom_density(data=test,aes(x=feature_3_impute))


colnames(test) <- c("feature_1_standard","feature_2_standard","feature_3_standard","feature_4_standard","id","date","y")


train
```

6.  Build a logistic regression on the training set to predict **'y'** being **(90+DPD)** using **"feature_1_standard"**, **"feature_2_standard"**, **"feature_3_standard"**, **"feature_4_standard"** as independent variables.

here i need to make the y being delinquent thee positive outcome in order to correctly interpreter the model results later because otherwise this is just too fucking complicated

```{r}
library(nnet)
train$y <- as.numeric(as.character(factor(train$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
delinquency_model <- multinom(y ~ feature_1_standard + feature_2_standard + feature_3_standard + feature_4_standard, data=train,family=binomial())
summary(delinquency_model)
```

7.  Report AUC on the **testing set**.

    <https://www.geeksforgeeks.org/auc-roc-curve/>

```{r}
    library(pROC)
    test$predicted_y <- predict(delinquency_model, newdata = test, type = "class")
    test$y_numeric <- as.numeric(as.character(factor(test$y, levels = c("90+DPD", "active"), labels = c(1, 0))))
    test$predicted_probs <- predict(delinquency_model, newdata = test, type = "probs")
    test$probs <- round(test$predicted_probs * 100, 1)

    test
    
    roc_curve <- roc(response = test$y_numeric, predictor = test$predicted_probs)
    plot(roc_curve, main = "ROC Curve for Multinomial Logistic Regression", col = "blue", lwd = 2)

    print(paste("AUC:", auc(roc_curve)))
  
    roc_metrics <- coords(roc_curve, x = "all", ret = c("threshold", "sensitivity", "specificity"))
    roc_metrics

```

7.  Report confusion matrix on the **testing set**.

    Since we are modelling delinquency of rent payments, it's in our best interest to bias our prediction towards higher true positives then lower false positives, as business is negatively effected by failure to predict delinquencies more so than the incorrect prediction of delinquencies.

    ```{r}

    ```

8.  Identify multicollinearity in the model.
